<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>rlify.agents package &mdash; RLify 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=d45e8c67"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="rlify.models package" href="rlify.models.html" />
    <link rel="prev" title="Welcome" href="readme_link.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            RLify
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readme_link.html">Welcome</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">rlify.agents package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.drl_agent">rlify.agents.drl_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent"><code class="docutils literal notranslate"><span class="pre">RL_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.TRAIN"><code class="docutils literal notranslate"><span class="pre">RL_Agent.TRAIN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.EVAL"><code class="docutils literal notranslate"><span class="pre">RL_Agent.EVAL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.init_tb_writer"><code class="docutils literal notranslate"><span class="pre">RL_Agent.init_tb_writer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">RL_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">RL_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">RL_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.get_train_metrics"><code class="docutils literal notranslate"><span class="pre">RL_Agent.get_train_metrics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.read_obs_space_properties"><code class="docutils literal notranslate"><span class="pre">RL_Agent.read_obs_space_properties()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.read_action_space_properties"><code class="docutils literal notranslate"><span class="pre">RL_Agent.read_action_space_properties()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.define_action_space"><code class="docutils literal notranslate"><span class="pre">RL_Agent.define_action_space()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__del__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__del__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">RL_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">RL_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.set_train_mode"><code class="docutils literal notranslate"><span class="pre">RL_Agent.set_train_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.set_eval_mode"><code class="docutils literal notranslate"><span class="pre">RL_Agent.set_eval_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.train_episodial"><code class="docutils literal notranslate"><span class="pre">RL_Agent.train_episodial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.train_n_steps"><code class="docutils literal notranslate"><span class="pre">RL_Agent.train_n_steps()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent._train_n_iters"><code class="docutils literal notranslate"><span class="pre">RL_Agent._train_n_iters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.set_num_parallel_env"><code class="docutils literal notranslate"><span class="pre">RL_Agent.set_num_parallel_env()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.act"><code class="docutils literal notranslate"><span class="pre">RL_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.load_highest_score_agent"><code class="docutils literal notranslate"><span class="pre">RL_Agent.load_highest_score_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.get_highest_score_agent_ckpt_path"><code class="docutils literal notranslate"><span class="pre">RL_Agent.get_highest_score_agent_ckpt_path()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">RL_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">RL_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.norm_obs"><code class="docutils literal notranslate"><span class="pre">RL_Agent.norm_obs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.pre_process_obs_for_act"><code class="docutils literal notranslate"><span class="pre">RL_Agent.pre_process_obs_for_act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.return_correct_actions_dim"><code class="docutils literal notranslate"><span class="pre">RL_Agent.return_correct_actions_dim()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.close_env_procs"><code class="docutils literal notranslate"><span class="pre">RL_Agent.close_env_procs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.set_intrisic_reward_func"><code class="docutils literal notranslate"><span class="pre">RL_Agent.set_intrisic_reward_func()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.intrisic_reward_func"><code class="docutils literal notranslate"><span class="pre">RL_Agent.intrisic_reward_func()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.collect_episode_obs"><code class="docutils literal notranslate"><span class="pre">RL_Agent.collect_episode_obs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">RL_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.get_last_collected_experiences"><code class="docutils literal notranslate"><span class="pre">RL_Agent.get_last_collected_experiences()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.clear_exp"><code class="docutils literal notranslate"><span class="pre">RL_Agent.clear_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__dict__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.__weakref__"><code class="docutils literal notranslate"><span class="pre">RL_Agent.__weakref__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">RL_Agent._abc_impl</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent.run_env"><code class="docutils literal notranslate"><span class="pre">RL_Agent.run_env()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.vdqn_agent">rlify.agents.vdqn_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.set_train_mode"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.set_train_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.set_eval_mode"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.set_eval_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.act_base"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.act_base()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.act"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent._get_dqn_experiences"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent._get_dqn_experiences()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.__annotations__"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">VDQN_Agent._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.dqn_agent">rlify.agents.dqn_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent"><code class="docutils literal notranslate"><span class="pre">DQN_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.init_target_update_rule"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.init_target_update_rule()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.set_train_mode"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.set_train_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.set_eval_mode"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.set_eval_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.hard_target_update"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.hard_target_update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.soft_target_update"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.soft_target_update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.act_base"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.act_base()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.act"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.__annotations__"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">DQN_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">DQN_Agent._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.ddpg_agent">rlify.agents.ddpg_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.set_train_mode"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.set_train_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.set_eval_mode"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.set_eval_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.hard_target_update"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.hard_target_update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.soft_target_update"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.soft_target_update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.actor_action"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.actor_action()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.get_actor_action_value"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.get_actor_action_value()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.act"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.__annotations__"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ddpg_agent.DDPG_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">DDPG_Agent._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.ppo_agent">rlify.agents.ppo_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent"><code class="docutils literal notranslate"><span class="pre">PPO_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.set_train_mode"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.set_train_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.set_eval_mode"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.set_eval_mode()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.set_num_parallel_env"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.set_num_parallel_env()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.act"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent._get_ppo_experiences"><code class="docutils literal notranslate"><span class="pre">PPO_Agent._get_ppo_experiences()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.__annotations__"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">PPO_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.ppo_agent.PPO_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">PPO_Agent._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.heuristic_agent">rlify.agents.heuristic_agent module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__init__"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.setup_models"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.setup_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.get_models_input_output_shape"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.get_models_input_output_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.save_agent"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.save_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.load_agent"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.load_agent()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.train"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.act"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.best_act_discrete"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.best_act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.best_act_cont"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.best_act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.reset_rnn_hidden"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.reset_rnn_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.update_policy"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.update_policy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.get_last_collected_experiences"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.get_last_collected_experiences()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.clear_exp"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.clear_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__annotations__"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__module__"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.heuristic_agent.Heuristic_Agent._abc_impl"><code class="docutils literal notranslate"><span class="pre">Heuristic_Agent._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.explorers">rlify.agents.explorers module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.explorers.Explorer"><code class="docutils literal notranslate"><span class="pre">Explorer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__init__"><code class="docutils literal notranslate"><span class="pre">Explorer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.explore"><code class="docutils literal notranslate"><span class="pre">Explorer.explore()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.update"><code class="docutils literal notranslate"><span class="pre">Explorer.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.act"><code class="docutils literal notranslate"><span class="pre">Explorer.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">Explorer.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__annotations__"><code class="docutils literal notranslate"><span class="pre">Explorer.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__dict__"><code class="docutils literal notranslate"><span class="pre">Explorer.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__module__"><code class="docutils literal notranslate"><span class="pre">Explorer.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer.__weakref__"><code class="docutils literal notranslate"><span class="pre">Explorer.__weakref__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.Explorer._abc_impl"><code class="docutils literal notranslate"><span class="pre">Explorer._abc_impl</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer"><code class="docutils literal notranslate"><span class="pre">RandomExplorer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.__init__"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.explore"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.explore()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.update"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.act"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer._act_discrete"><code class="docutils literal notranslate"><span class="pre">RandomExplorer._act_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer._act_cont"><code class="docutils literal notranslate"><span class="pre">RandomExplorer._act_cont()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.__annotations__"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer.__module__"><code class="docutils literal notranslate"><span class="pre">RandomExplorer.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.RandomExplorer._abc_impl"><code class="docutils literal notranslate"><span class="pre">RandomExplorer._abc_impl</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.__init__"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.explore"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.explore()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.update"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.act"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.act()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.__abstractmethods__"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.__abstractmethods__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.__annotations__"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer.__module__"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.explorers.HeuristicExplorer._abc_impl"><code class="docutils literal notranslate"><span class="pre">HeuristicExplorer._abc_impl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.action_spaces_utils">rlify.agents.action_spaces_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW"><code class="docutils literal notranslate"><span class="pre">MCAW</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.__init__"><code class="docutils literal notranslate"><span class="pre">MCAW.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.sample"><code class="docutils literal notranslate"><span class="pre">MCAW.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.log_prob"><code class="docutils literal notranslate"><span class="pre">MCAW.log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.loc"><code class="docutils literal notranslate"><span class="pre">MCAW.loc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.scale"><code class="docutils literal notranslate"><span class="pre">MCAW.scale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.entropy"><code class="docutils literal notranslate"><span class="pre">MCAW.entropy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.__dict__"><code class="docutils literal notranslate"><span class="pre">MCAW.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.__module__"><code class="docutils literal notranslate"><span class="pre">MCAW.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MCAW.__weakref__"><code class="docutils literal notranslate"><span class="pre">MCAW.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.action_spaces_utils.CAW"><code class="docutils literal notranslate"><span class="pre">CAW</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.CAW.__init__"><code class="docutils literal notranslate"><span class="pre">CAW.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.CAW.sample"><code class="docutils literal notranslate"><span class="pre">CAW.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.CAW.__module__"><code class="docutils literal notranslate"><span class="pre">CAW.__module__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA"><code class="docutils literal notranslate"><span class="pre">MDA</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.__init__"><code class="docutils literal notranslate"><span class="pre">MDA.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.sample"><code class="docutils literal notranslate"><span class="pre">MDA.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.log_prob"><code class="docutils literal notranslate"><span class="pre">MDA.log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.probs"><code class="docutils literal notranslate"><span class="pre">MDA.probs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.entropy"><code class="docutils literal notranslate"><span class="pre">MDA.entropy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.__dict__"><code class="docutils literal notranslate"><span class="pre">MDA.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.__module__"><code class="docutils literal notranslate"><span class="pre">MDA.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.action_spaces_utils.MDA.__weakref__"><code class="docutils literal notranslate"><span class="pre">MDA.__weakref__</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlify.agents.agent_utils">rlify.agents.agent_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.calc_gaes"><code class="docutils literal notranslate"><span class="pre">calc_gaes()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.calc_returns"><code class="docutils literal notranslate"><span class="pre">calc_returns()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper.dict_types"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper.dict_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper.__init__"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper.__dict__"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper.__module__"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsShapeWraper.__weakref__"><code class="docutils literal notranslate"><span class="pre">ObsShapeWraper.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper"><code class="docutils literal notranslate"><span class="pre">ObsWraper</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__init__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.update_shape"><code class="docutils literal notranslate"><span class="pre">ObsWraper.update_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.init_from_dict"><code class="docutils literal notranslate"><span class="pre">ObsWraper.init_from_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.init_from_list_obsWrapper_obs"><code class="docutils literal notranslate"><span class="pre">ObsWraper.init_from_list_obsWrapper_obs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.init_from_list_generic_data"><code class="docutils literal notranslate"><span class="pre">ObsWraper.init_from_list_generic_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper._init_from_none_"><code class="docutils literal notranslate"><span class="pre">ObsWraper._init_from_none_()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__setitem__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__setitem__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__delitem__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__delitem__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__iter__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__iter__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__getitem__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__getitem__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.slice_tensors"><code class="docutils literal notranslate"><span class="pre">ObsWraper.slice_tensors()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.keys"><code class="docutils literal notranslate"><span class="pre">ObsWraper.keys()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.items"><code class="docutils literal notranslate"><span class="pre">ObsWraper.items()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.values"><code class="docutils literal notranslate"><span class="pre">ObsWraper.values()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__len__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__len__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__str__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__str__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__repr__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__repr__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__mul__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__mul__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__add__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__add__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__neg__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__neg__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__sub__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__sub__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__truediv__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__truediv__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.unsqueeze"><code class="docutils literal notranslate"><span class="pre">ObsWraper.unsqueeze()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.squeeze"><code class="docutils literal notranslate"><span class="pre">ObsWraper.squeeze()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.get_as_tensors"><code class="docutils literal notranslate"><span class="pre">ObsWraper.get_as_tensors()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.np_cat"><code class="docutils literal notranslate"><span class="pre">ObsWraper.np_cat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.np_append"><code class="docutils literal notranslate"><span class="pre">ObsWraper.np_append()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.cat"><code class="docutils literal notranslate"><span class="pre">ObsWraper.cat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.np_zero_roll"><code class="docutils literal notranslate"><span class="pre">ObsWraper.np_zero_roll()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.np_roll"><code class="docutils literal notranslate"><span class="pre">ObsWraper.np_roll()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__dict__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__module__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper.__weakref__"><code class="docutils literal notranslate"><span class="pre">ObsWraper.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.__init__"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.__len__"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.__len__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.append"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.append()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.init_buffers"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.init_buffers()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.clear"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.clear()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_episodes_accumulated_rewards"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_episodes_accumulated_rewards()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_episode_end_indices"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_episode_end_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_episode_start_indices"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_episode_start_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_first_episodes"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_num_samples_of_k_first_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_last_episodes"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_num_samples_of_k_last_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_last_episodes"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_last_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_first_episodes"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_first_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_first_samples"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_first_samples()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_last_samples"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_last_samples()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_all_buffers"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_all_buffers()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.get_buffers_at"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.get_buffers_at()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.sample_random_episodes"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.sample_random_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.sample_random_batch"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.sample_random_batch()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.__dict__"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.__module__"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay.__weakref__"><code class="docutils literal notranslate"><span class="pre">ExperienceReplay.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__init__"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.init_buffers"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.init_buffers()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.append"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.append()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.get_last_episodes"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.get_last_episodes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__annotations__"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.__annotations__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__module__"><code class="docutils literal notranslate"><span class="pre">ForgettingExperienceReplay.__module__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.worker"><code class="docutils literal notranslate"><span class="pre">worker()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv"><code class="docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.__init__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.__del__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.__del__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.change_env"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.change_env()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.get_envs"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.get_envs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.reset"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.reset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.step"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.close_procs"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.close_procs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.render"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.render()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.__dict__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.__module__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv.__weakref__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.__init__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.change_env"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.change_env()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.get_envs"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.get_envs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.reset"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.reset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.step"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.render"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.render()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.__del__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.__del__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.close_procs"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.close_procs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.__dict__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.__module__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.ParallelEnv_m.__weakref__"><code class="docutils literal notranslate"><span class="pre">ParallelEnv_m.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.__init__"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.change_env"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.change_env()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.get_envs"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.get_envs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.reset"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.reset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.step"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.render"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.render()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.close_procs"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.close_procs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.__dict__"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.__module__"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.SingleEnv_m.__weakref__"><code class="docutils literal notranslate"><span class="pre">SingleEnv_m.__weakref__</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics"><code class="docutils literal notranslate"><span class="pre">TrainMetrics</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__dict__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__dict__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__module__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__module__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__weakref__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__weakref__</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__init__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.add"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.add()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.on_epoch_end"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.on_epoch_end()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.get_metrcis_df"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.get_metrcis_df()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__iter__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__iter__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__next__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__next__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rlify.agents.agent_utils.TrainMetrics.__getitem__"><code class="docutils literal notranslate"><span class="pre">TrainMetrics.__getitem__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlify.models.html">rlify.models package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">RLify</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">rlify.agents package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/rlify.agents.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rlify-agents-package">
<h1>rlify.agents package<a class="headerlink" href="#rlify-agents-package" title="Link to this heading"></a></h1>
<p>This package contains all agents and their helper classes.</p>
<section id="module-rlify.agents.drl_agent">
<span id="rlify-agents-drl-agent-module"></span><h2>rlify.agents.drl_agent module<a class="headerlink" href="#module-rlify.agents.drl_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.drl_agent.</span></span><span class="sig-name descname"><span class="pre">RL_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_mem_size=10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_envs=4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_epochs_per_update=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr=0.0003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_class=&lt;class</span> <span class="pre">'rlify.agents.agent_utils.ExperienceReplay'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discount_factor=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_normalization=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_dir='./tensorboard'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>RL_Agent is an abstract class that defines the basic structure of an RL agent.
It is used as a base class for all RL agents.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.TRAIN">
<span class="sig-name descname"><span class="pre">TRAIN</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.TRAIN" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.EVAL">
<span class="sig-name descname"><span class="pre">EVAL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.EVAL" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_mem_size=10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_envs=4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_epochs_per_update=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr=0.0003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_class=&lt;class</span> <span class="pre">'rlify.agents.agent_utils.ExperienceReplay'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discount_factor=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_normalization=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_dir='./tensorboard'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_space</strong> (<em>gym.spaces</em>)  observation space of the environment</p></li>
<li><p><strong>action_space</strong> (<em>gym.spaces</em>)  action space of the environment</p></li>
<li><p><strong>max_mem_size</strong> (<em>int</em><em>, </em><em>optional</em>)  maximum size of the experience replay buffer. Defaults to 10e6.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>)  batch size for training. Defaults to 256.</p></li>
<li><p><strong>explorer</strong> (<a class="reference internal" href="#rlify.agents.explorers.Explorer" title="rlify.agents.explorers.Explorer"><em>Explorer</em></a><em>, </em><em>optional</em>)  exploration method. Defaults to RandomExplorer().</p></li>
<li><p><strong>num_parallel_envs</strong> (<em>int</em><em>, </em><em>optional</em>)  number of parallel environments. Defaults to 4.</p></li>
<li><p><strong>num_epochs_per_update</strong> (<em>int</em>)  Training epochs per update. Defaults to 10.</p></li>
<li><p><strong>lr</strong> (<em>float</em><em>, </em><em>optional</em>)  learning rate. Defaults to 0.0001.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>)  device to run on. Defaults to None.</p></li>
<li><p><strong>experience_class</strong> (<em>object</em><em>, </em><em>optional</em>)  experience replay class. Defaults to ExperienceReplay.            discount_factor (float, optional): discount factor. Defaults to 0.99.</p></li>
<li><p><strong>reward_normalization</strong> (<em>bool</em><em>, </em><em>optional</em>)  whether to normalize the rewards by maximum absolut value. Defaults to True.</p></li>
<li><p><strong>tensorboard_dir</strong> (<em>str</em><em>, </em><em>optional</em>)  tensorboard directory. Defaults to ./tensorboard.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.init_tb_writer">
<span class="sig-name descname"><span class="pre">init_tb_writer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensorboard_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.init_tb_writer" title="Link to this definition"></a></dt>
<dd><p>Initializes tensorboard writer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensorboard_dir</strong> (<em>str</em>)  tensorboard directory</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.get_models_input_output_shape">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Calculates the input and output shapes of the models
:type obs_space: 
:param obs_space: observation space
:type action_space: 
:param action_space: action space</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary containing the input and output shapes of the models</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.setup_models">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Initializes the NN models</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.update_policy">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>Updates the models and according to the agnets logic</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.get_train_metrics">
<span class="sig-name descname"><span class="pre">get_train_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.get_train_metrics" title="Link to this definition"></a></dt>
<dd><p>Returns the training metrics</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.read_obs_space_properties">
<span class="sig-name descname"><span class="pre">read_obs_space_properties</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.read_obs_space_properties" title="Link to this definition"></a></dt>
<dd><p>Returns the observation space properties</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.read_action_space_properties">
<span class="sig-name descname"><span class="pre">read_action_space_properties</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.read_action_space_properties" title="Link to this definition"></a></dt>
<dd><p>Returns the action space properties</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.define_action_space">
<span class="sig-name descname"><span class="pre">define_action_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.define_action_space" title="Link to this definition"></a></dt>
<dd><p>Defines the action space</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__del__">
<span class="sig-name descname"><span class="pre">__del__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__del__" title="Link to this definition"></a></dt>
<dd><p>Destructor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.save_agent">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.load_agent">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.set_train_mode">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_train_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.set_train_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to train mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.set_eval_mode">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_eval_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.set_eval_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to eval mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.train_episodial">
<span class="sig-name descname"><span class="pre">train_episodial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episodes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_episode_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_tqdm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.train_episodial" title="Link to this definition"></a></dt>
<dd><p>Trains the agent for a given number of episodes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>gym.Env</em>)  the environment to train on</p></li>
<li><p><strong>n_episodes</strong> (<em>int</em>)  number of episodes to train</p></li>
<li><p><strong>max_episode_len</strong> (<em>int</em><em>, </em><em>optional</em>)  maximum episode length - truncates after that. Defaults to None.</p></li>
<li><p><strong>disable_tqdm</strong> (<em>bool</em><em>, </em><em>optional</em>)  disable tqdm. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>train rewards</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.train_n_steps">
<span class="sig-name descname"><span class="pre">train_n_steps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_episode_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_tqdm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.train_n_steps" title="Link to this definition"></a></dt>
<dd><p>Trains the agent for a given number of steps</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>gym.Env</em>)  the environment to train on</p></li>
<li><p><strong>n_steps</strong> (<em>int</em>)  number of steps to train</p></li>
<li><p><strong>max_episode_len</strong> (<em>int</em><em>, </em><em>optional</em>)  maximum episode length - truncates after that. Defaults to None.</p></li>
<li><p><strong>disable_tqdm</strong> (<em>bool</em><em>, </em><em>optional</em>)  disable tqdm. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>train rewards</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent._train_n_iters">
<span class="sig-name descname"><span class="pre">_train_n_iters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_episode_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_tqdm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent._train_n_iters" title="Link to this definition"></a></dt>
<dd><p>Trains the agent for a given number of steps</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>gym.Env</em>)  the environment to train on</p></li>
<li><p><strong>n_iters</strong> (<em>int</em>)  number of steps/episodes to train</p></li>
<li><p><strong>episodes</strong> (<em>bool</em><em>, </em><em>optional</em>)  whether to train for episodes or steps. Defaults to False.</p></li>
<li><p><strong>max_episode_len</strong> (<em>int</em><em>, </em><em>optional</em>)  maximum episode length - truncates after that. Defaults to None.</p></li>
<li><p><strong>disable_tqdm</strong> (<em>bool</em><em>, </em><em>optional</em>)  disable tqdm. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>train rewards</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.set_num_parallel_env">
<span class="sig-name descname"><span class="pre">set_num_parallel_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_parallel_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.set_num_parallel_env" title="Link to this definition"></a></dt>
<dd><p>Sets the number of parallel environments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_parallel_envs</strong> (<em>int</em>)  number of parallel environments</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.act">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.load_highest_score_agent">
<span class="sig-name descname"><span class="pre">load_highest_score_agent</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.load_highest_score_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the highest score agent from training</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.get_highest_score_agent_ckpt_path">
<span class="sig-name descname"><span class="pre">get_highest_score_agent_ckpt_path</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.get_highest_score_agent_ckpt_path" title="Link to this definition"></a></dt>
<dd><p>Returns the path of the highest score agent from training</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.best_act_discrete">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.best_act_cont">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.norm_obs">
<span class="sig-name descname"><span class="pre">norm_obs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.norm_obs" title="Link to this definition"></a></dt>
<dd><p>Normalizes the observations according to the pre given normalization parameters [future api - currently not availble]</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.pre_process_obs_for_act">
<span class="sig-name descname"><span class="pre">pre_process_obs_for_act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.pre_process_obs_for_act" title="Link to this definition"></a></dt>
<dd><p>Pre processes the observations for act</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type">[&lt;built-in function array&gt;, &lt;class rlify.agents.agent_utils.ObsWraper&gt;, &lt;class dict&gt;]</span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The pre processed observations an ObsWraper object with the right dims</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.return_correct_actions_dim">
<span class="sig-name descname"><span class="pre">return_correct_actions_dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.return_correct_actions_dim" title="Link to this definition"></a></dt>
<dd><p>Returns the correct actions dimention</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>)  The selected actions</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.close_env_procs">
<span class="sig-name descname"><span class="pre">close_env_procs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.close_env_procs" title="Link to this definition"></a></dt>
<dd><p>Closes the environment processes</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.set_intrisic_reward_func">
<span class="sig-name descname"><span class="pre">set_intrisic_reward_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.set_intrisic_reward_func" title="Link to this definition"></a></dt>
<dd><p>sets the agents inner reward function to a custom function that takes state, action, reward and returns reward for the algorithm:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create some agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">PPO_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span> <span class="n">tensorboard_dir</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">dummy_reward_func</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reward</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">agent</span><span class="o">.</span><span class="n">set_intrisic_reward_func</span><span class="p">(</span><span class="n">dummy_reward_func</span><span class="p">)</span>
<span class="c1"># now train normaly</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>func</strong> (<em>function</em>)  a function that takes state, action, reward and returns reward for the algorithm</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.intrisic_reward_func">
<span class="sig-name descname"><span class="pre">intrisic_reward_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.intrisic_reward_func" title="Link to this definition"></a></dt>
<dd><p>Calculates the agents inner reward</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.collect_episode_obs">
<span class="sig-name descname"><span class="pre">collect_episode_obs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_episode_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_to_collect_in_parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.collect_episode_obs" title="Link to this definition"></a></dt>
<dd><p>Collects observations from the environment</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>gym.env</em>)  gym environment</p></li>
<li><p><strong>max_episode_len</strong> (<em>int</em><em>, </em><em>optional</em>)  maximum episode length. Defaults to None.</p></li>
<li><p><strong>num_to_collect_in_parallel</strong> (<em>int</em><em>, </em><em>optional</em>)  number of parallel environments. Defaults to None.</p></li>
<li><p><strong>env_funcs</strong> (<em>dict</em><em>, </em><em>optional</em>)  dictionary of env functions mapping to call on the environment. Defaults to {step: step, reset: reset}.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>total reward collected</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.reset_rnn_hidden">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>if agent uses rnn, when the hidden states are reset.
this callback is called in many places so please impliment it in you agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.get_last_collected_experiences">
<span class="sig-name descname"><span class="pre">get_last_collected_experiences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number_of_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.get_last_collected_experiences" title="Link to this definition"></a></dt>
<dd><p>returns the last collected experiences</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>number_of_episodes</strong> (<em>int</em>)  number of episodes to return</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.clear_exp">
<span class="sig-name descname"><span class="pre">clear_exp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.clear_exp" title="Link to this definition"></a></dt>
<dd><p>clears the experience replay buffer</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({'act',</span> <span class="pre">'best_act_cont',</span> <span class="pre">'best_act_discrete',</span> <span class="pre">'get_models_input_output_shape',</span> <span class="pre">'load_agent',</span> <span class="pre">'reset_rnn_hidden',</span> <span class="pre">'save_agent',</span> <span class="pre">'set_eval_mode',</span> <span class="pre">'set_train_mode',</span> <span class="pre">'setup_models',</span> <span class="pre">'update_policy'})</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.drl_agent',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">RL_Agent</span> <span class="pre">is</span> <span class="pre">an</span> <span class="pre">abstract</span> <span class="pre">class</span> <span class="pre">that</span> <span class="pre">defines</span> <span class="pre">the</span> <span class="pre">basic</span> <span class="pre">structure</span> <span class="pre">of</span> <span class="pre">an</span> <span class="pre">RL</span> <span class="pre">agent.\n</span>&#160;&#160;&#160; <span class="pre">It</span> <span class="pre">is</span> <span class="pre">used</span> <span class="pre">as</span> <span class="pre">a</span> <span class="pre">base</span> <span class="pre">class</span> <span class="pre">for</span> <span class="pre">all</span> <span class="pre">RL</span> <span class="pre">agents.\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'TRAIN':</span> <span class="pre">0,</span> <span class="pre">'EVAL':</span> <span class="pre">1,</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.__init__&gt;,</span> <span class="pre">'init_tb_writer':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.init_tb_writer&gt;,</span> <span class="pre">'get_models_input_output_shape':</span> <span class="pre">&lt;staticmethod(&lt;function</span> <span class="pre">RL_Agent.get_models_input_output_shape&gt;)&gt;,</span> <span class="pre">'setup_models':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.setup_models&gt;,</span> <span class="pre">'update_policy':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.update_policy&gt;,</span> <span class="pre">'get_train_metrics':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.get_train_metrics&gt;,</span> <span class="pre">'read_obs_space_properties':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.read_obs_space_properties&gt;,</span> <span class="pre">'read_action_space_properties':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.read_action_space_properties&gt;,</span> <span class="pre">'define_action_space':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.define_action_space&gt;,</span> <span class="pre">'__del__':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.__del__&gt;,</span> <span class="pre">'save_agent':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.save_agent&gt;,</span> <span class="pre">'load_agent':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.load_agent&gt;,</span> <span class="pre">'set_train_mode':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.set_train_mode&gt;,</span> <span class="pre">'set_eval_mode':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.set_eval_mode&gt;,</span> <span class="pre">'train_episodial':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.train_episodial&gt;,</span> <span class="pre">'train_n_steps':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.train_n_steps&gt;,</span> <span class="pre">'_train_n_iters':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent._train_n_iters&gt;,</span> <span class="pre">'set_num_parallel_env':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.set_num_parallel_env&gt;,</span> <span class="pre">'act':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.act&gt;,</span> <span class="pre">'load_highest_score_agent':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.load_highest_score_agent&gt;,</span> <span class="pre">'get_highest_score_agent_ckpt_path':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.get_highest_score_agent_ckpt_path&gt;,</span> <span class="pre">'best_act_discrete':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.best_act_discrete&gt;,</span> <span class="pre">'best_act_cont':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.best_act_cont&gt;,</span> <span class="pre">'norm_obs':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.norm_obs&gt;,</span> <span class="pre">'pre_process_obs_for_act':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.pre_process_obs_for_act&gt;,</span> <span class="pre">'return_correct_actions_dim':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.return_correct_actions_dim&gt;,</span> <span class="pre">'close_env_procs':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.close_env_procs&gt;,</span> <span class="pre">'set_intrisic_reward_func':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.set_intrisic_reward_func&gt;,</span> <span class="pre">'intrisic_reward_func':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.intrisic_reward_func&gt;,</span> <span class="pre">'collect_episode_obs':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.collect_episode_obs&gt;,</span> <span class="pre">'reset_rnn_hidden':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.reset_rnn_hidden&gt;,</span> <span class="pre">'get_last_collected_experiences':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.get_last_collected_experiences&gt;,</span> <span class="pre">'clear_exp':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.clear_exp&gt;,</span> <span class="pre">'run_env':</span> <span class="pre">&lt;function</span> <span class="pre">RL_Agent.run_env&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'RL_Agent'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'RL_Agent'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__abstractmethods__':</span> <span class="pre">frozenset({'best_act_discrete',</span> <span class="pre">'save_agent',</span> <span class="pre">'load_agent',</span> <span class="pre">'set_train_mode',</span> <span class="pre">'update_policy',</span> <span class="pre">'setup_models',</span> <span class="pre">'get_models_input_output_shape',</span> <span class="pre">'act',</span> <span class="pre">'set_eval_mode',</span> <span class="pre">'best_act_cont',</span> <span class="pre">'reset_rnn_hidden'}),</span> <span class="pre">'_abc_impl':</span> <span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.drl_agent'</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.drl_agent.RL_Agent.run_env">
<span class="sig-name descname"><span class="pre">run_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_runs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.drl_agent.RL_Agent.run_env" title="Link to this definition"></a></dt>
<dd><p>Runs the environment with the agent in eval mode
:type env: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Env</span></code></span>
:param env: the environment to run
:type env: gym.Env
:type best_act: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>
:param best_act: whether to use the best action or the agents action. Defaults to True.
:type best_act: bool, optional
:type num_runs: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>
:param num_runs: number of runs. Defaults to 1.
:type num_runs: int, optional</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.vdqn_agent">
<span id="rlify-agents-vdqn-agent-module"></span><h2>rlify.agents.vdqn_agent module<a class="headerlink" href="#module-rlify.agents.vdqn_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.vdqn_agent.</span></span><span class="sig-name descname"><span class="pre">VDQN_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dqn_reg=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_exploit=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent" title="rlify.agents.drl_agent.RL_Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">RL_Agent</span></code></a></p>
<p>DQN Agent</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dqn_reg=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_exploit=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.__init__" title="Link to this definition"></a></dt>
<dd><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env_name</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">models_shapes</span> <span class="o">=</span> <span class="n">VDQN_Agent</span><span class="o">.</span><span class="n">get_models_input_output_shape</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Q_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">Q_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">Q_model</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">Q_input_shape</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="n">Q_out_shape</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">VDQN_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">max_mem_size</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_parallel_envs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                    <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> <span class="n">Q_model</span><span class="o">=</span><span class="n">Q_model</span><span class="p">,</span> <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">target_update</span><span class="o">=</span><span class="s1">&#39;hard[update_freq=10]&#39;</span><span class="p">,</span> <span class="n">tensorboard_dir</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_epochs_per_update</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">train_stats</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">train_n_steps</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">80000</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dqn_reg</strong> (<em>float</em><em>, </em><em>optional</em>)  L2 regularization for the Q network. Defaults to 0.0.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>)  Batch size for training. Defaults to 64.</p></li>
<li><p><strong>soft_exploit</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to use soft exploit. Defaults to True.</p></li>
<li><p><strong>explorer</strong> (<a class="reference internal" href="#rlify.agents.explorers.Explorer" title="rlify.agents.explorers.Explorer"><em>Explorer</em></a><em>, </em><em>optional</em>)  The explorer to use. Defaults to RandomExplorer().</p></li>
<li><p><strong>args</strong>  Additional RL_Agent arguments.</p></li>
<li><p><strong>kwargs</strong>  Additional RL_Agent arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.setup_models">
<span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Initializes the Q Model and optimizer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.get_models_input_output_shape">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Calculates the input and output shapes of the models
:type obs_space: 
:param obs_space: observation space
:type action_space: 
:param action_space: action space</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary containing the input and output shapes of the models</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.set_train_mode">
<span class="sig-name descname"><span class="pre">set_train_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.set_train_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to train mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.set_eval_mode">
<span class="sig-name descname"><span class="pre">set_eval_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.set_eval_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to eval mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.best_act_cont">
<span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.best_act_discrete">
<span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.save_agent">
<span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.load_agent">
<span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.act_base">
<span class="sig-name descname"><span class="pre">act_base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.act_base" title="Link to this definition"></a></dt>
<dd><p>Returns the Q values for the given observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>np.array</em>)  The observations.</p></li>
<li><p><strong>num_obs</strong> (<em>int</em><em>, </em><em>optional</em>)  The number of observations. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The Q values (torch.tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.reset_rnn_hidden">
<span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>if agent uses rnn, when the hidden states are reset.
this callback is called in many places so please impliment it in you agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent._get_dqn_experiences">
<span class="sig-name descname"><span class="pre">_get_dqn_experiences</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent._get_dqn_experiences" title="Link to this definition"></a></dt>
<dd><p>loads experiences from the replay buffer and returns them as tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>(states, actions, rewards, dones, truncated, next_states, returns)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.update_policy">
<span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>Updates the models and according to the agnets logic</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.vdqn_agent'</span></em><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.vdqn_agent.VDQN_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.vdqn_agent.VDQN_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.dqn_agent">
<span id="rlify-agents-dqn-agent-module"></span><h2>rlify.agents.dqn_agent module<a class="headerlink" href="#module-rlify.agents.dqn_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.dqn_agent.</span></span><span class="sig-name descname"><span class="pre">DQN_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hard[update_freq=10]'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.vdqn_agent.VDQN_Agent" title="rlify.agents.vdqn_agent.VDQN_Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">VDQN_Agent</span></code></a></p>
<p>DQN Agent</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hard[update_freq=10]'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.__init__" title="Link to this definition"></a></dt>
<dd><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env_name</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">models_shapes</span> <span class="o">=</span> <span class="n">DQN_Agent</span><span class="o">.</span><span class="n">get_models_input_output_shape</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Q_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">Q_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">Q_model</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">Q_input_shape</span><span class="p">,</span> <span class="n">out_shape</span><span class="o">=</span><span class="n">Q_out_shape</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">DQN_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">max_mem_size</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_parallel_envs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                    <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> <span class="n">Q_model</span><span class="o">=</span><span class="n">Q_model</span><span class="p">,</span> <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">target_update</span><span class="o">=</span><span class="s1">&#39;hard[update_freq=10]&#39;</span><span class="p">,</span> <span class="n">tensorboard_dir</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_epochs_per_update</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">train_stats</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">train_n_steps</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">80000</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_update</strong> (<em>str</em>)  soft[tau=0.01] or hard[update_freq=10] target update</p></li>
<li><p><strong>args</strong>  Additional VDQN_Agent arguments.</p></li>
<li><p><strong>kwargs</strong>  Additional VDQN_Agent arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.setup_models">
<span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Initializes the Q and target Q networks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.get_models_input_output_shape">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Calculates the input and output shapes of the models
:type obs_space: 
:param obs_space: observation space
:type action_space: 
:param action_space: action space</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary containing the input and output shapes of the models</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.init_target_update_rule">
<span class="sig-name descname"><span class="pre">init_target_update_rule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_update</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.init_target_update_rule" title="Link to this definition"></a></dt>
<dd><p>Initializes the target update rule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>target_update</strong> (<em>str</em>)  soft[tau=0.01] or hard[update_freq=10] target update</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.set_train_mode">
<span class="sig-name descname"><span class="pre">set_train_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.set_train_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to train mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.set_eval_mode">
<span class="sig-name descname"><span class="pre">set_eval_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.set_eval_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to eval mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.hard_target_update">
<span class="sig-name descname"><span class="pre">hard_target_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">manual_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.hard_target_update" title="Link to this definition"></a></dt>
<dd><p>Hard update model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>manual_update</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to force an update. Defaults to False - in case of force update target_update_counter is not updated.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.soft_target_update">
<span class="sig-name descname"><span class="pre">soft_target_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.soft_target_update" title="Link to this definition"></a></dt>
<dd><p>Soft update model parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.best_act_cont">
<span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.best_act_discrete">
<span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.save_agent">
<span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.load_agent">
<span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.act_base">
<span class="sig-name descname"><span class="pre">act_base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.act_base" title="Link to this definition"></a></dt>
<dd><p>Returns the Q values for the given observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>np.array</em>)  The observations.</p></li>
<li><p><strong>num_obs</strong> (<em>int</em><em>, </em><em>optional</em>)  The number of observations. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Q values (torch.tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.reset_rnn_hidden">
<span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>if agent uses rnn, when the hidden states are reset.
this callback is called in many places so please impliment it in you agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.update_policy">
<span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>Updates the policy.
Using the DQN algorithm.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.dqn_agent'</span></em><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.dqn_agent.DQN_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.dqn_agent.DQN_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.ddpg_agent">
<span id="rlify-agents-ddpg-agent-module"></span><h2>rlify.agents.ddpg_agent module<a class="headerlink" href="#module-rlify.agents.ddpg_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.ddpg_agent.</span></span><span class="sig-name descname"><span class="pre">DDPG_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_mle_model</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.dqn_agent.DQN_Agent" title="rlify.agents.dqn_agent.DQN_Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">DQN_Agent</span></code></a></p>
<p>DQN Agent</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_mle_model</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.__init__" title="Link to this definition"></a></dt>
<dd><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env_name</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">models_shapes</span> <span class="o">=</span> <span class="n">DDPG_Agent</span><span class="o">.</span><span class="n">get_models_input_output_shape</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Q_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">Q_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_model&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">Q_mle_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_mle_model&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">Q_mle_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;Q_mle_model&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">Q_model</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="n">Q_input_shape</span><span class="p">,</span>
    <span class="n">out_shape</span><span class="o">=</span><span class="n">Q_out_shape</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">Q_mle_model</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="n">Q_mle_input_shape</span><span class="p">,</span>
    <span class="n">out_shape</span><span class="o">=</span><span class="n">Q_mle_out_shape</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">DDPG_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">Q_model</span><span class="o">=</span><span class="n">Q_model</span><span class="p">,</span> <span class="n">Q_mle_model</span><span class="o">=</span><span class="n">Q_mle_model</span><span class="p">)</span>
<span class="n">train_stats</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">train_n_steps</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env_c</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">80000</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Q_mle_model</strong> (<a class="reference internal" href="rlify.models.html#rlify.models.base_model.BaseModel" title="rlify.models.base_model.BaseModel"><em>BaseModel</em></a>)  The MLE model to use.</p></li>
<li><p><strong>args</strong>  Additional DQN_Agent arguments.</p></li>
<li><p><strong>kwargs</strong>  Additional DQN_Agent arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.setup_models">
<span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Initializes the Q, target Q and MLE networks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.get_models_input_output_shape">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Returns the input and output shapes of the Q model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.set_train_mode">
<span class="sig-name descname"><span class="pre">set_train_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.set_train_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to train mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.set_eval_mode">
<span class="sig-name descname"><span class="pre">set_eval_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.set_eval_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to eval mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.hard_target_update">
<span class="sig-name descname"><span class="pre">hard_target_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">manual_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.hard_target_update" title="Link to this definition"></a></dt>
<dd><p>Hard update model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>manual_update</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to force an update. Defaults to False - in case of force update target_update_counter is not updated.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.soft_target_update">
<span class="sig-name descname"><span class="pre">soft_target_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.soft_target_update" title="Link to this definition"></a></dt>
<dd><p>Soft update model parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.best_act_cont">
<span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type">[&lt;built-in function array&gt;, &lt;built-in method tensor of type object at 0x7fc2ed5957c0&gt;]</span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.best_act_discrete">
<span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type">[&lt;built-in function array&gt;, &lt;built-in method tensor of type object at 0x7fc2ed5957c0&gt;]</span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.reset_rnn_hidden">
<span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>if agent uses rnn, when the hidden states are reset.
this callback is called in many places so please impliment it in you agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.save_agent">
<span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.load_agent">
<span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.actor_action">
<span class="sig-name descname"><span class="pre">actor_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.actor_action" title="Link to this definition"></a></dt>
<dd><p>Returns the actor action for a batch of observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>np.ndarray</em><em>, </em><em>torch.tensor</em>)  The observations to act on</p></li>
<li><p><strong>dones</strong> (<em>np.ndarray</em><em>, </em><em>torch.tensor</em>)  The dones of the observations</p></li>
<li><p><strong>num_obs</strong> (<em>int</em><em>, </em><em>optional</em>)  The number of observations to act on. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The actions</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.get_actor_action_value">
<span class="sig-name descname"><span class="pre">get_actor_action_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.get_actor_action_value" title="Link to this definition"></a></dt>
<dd><p>Returns the actor action value for a batch of observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> (<em>torch.tensor</em>)  The observations to act on</p></li>
<li><p><strong>dones</strong> (<em>torch.tensor</em>)  The dones of the observations</p></li>
<li><p><strong>actions</strong> (<em>torch.tensor</em>)  The actions to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The actions values</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<span class="sphinx_autodoc_typehints-type">[&lt;built-in function array&gt;]</span>)  The observations to act on</p></li>
<li><p><strong>num_obs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.update_policy">
<span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>Updates the policy, using the DDPG algorithm.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.ddpg_agent'</span></em><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ddpg_agent.DDPG_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.ddpg_agent.DDPG_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.ppo_agent">
<span id="rlify-agents-ppo-agent-module"></span><h2>rlify.agents.ppo_agent module<a class="headerlink" href="#module-rlify.agents.ppo_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.ppo_agent.</span></span><span class="sig-name descname"><span class="pre">PPO_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy_nn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">critic_nn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entropy_coeff=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_epochs_per_update=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_div_thresh=0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_param=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_class=&lt;class</span> <span class="pre">'rlify.agents.agent_utils.ForgettingExperienceReplay'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent" title="rlify.agents.drl_agent.RL_Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">RL_Agent</span></code></a></p>
<p>Proximal Policy Optimization (PPO) reinforcement learning agent.
Inherits from RL_Agent.</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy_nn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">critic_nn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size=1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entropy_coeff=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_epochs_per_update=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_div_thresh=0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_param=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_class=&lt;class</span> <span class="pre">'rlify.agents.agent_utils.ForgettingExperienceReplay'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explorer=&lt;rlify.agents.explorers.RandomExplorer</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.__init__" title="Link to this definition"></a></dt>
<dd><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env_name</span> <span class="o">=</span> <span class="s1">&#39;Pendulum-v1&#39;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">models_shapes</span> <span class="o">=</span> <span class="n">PPO_Agent</span><span class="o">.</span><span class="n">get_models_input_output_shape</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">policy_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;policy_nn&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">policy_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;policy_nn&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">critic_input_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;critic_nn&quot;</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span>
<span class="n">critic_out_shape</span> <span class="o">=</span> <span class="n">models_shapes</span><span class="p">[</span><span class="s2">&quot;critic_nn&quot;</span><span class="p">][</span><span class="s2">&quot;out_shape&quot;</span><span class="p">]</span>
<span class="n">policy_nn</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">policy_input_shape</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">out_shape</span><span class="o">=</span><span class="n">policy_out_shape</span><span class="p">)</span>
<span class="n">critic_nn</span> <span class="o">=</span> <span class="n">fc</span><span class="o">.</span><span class="n">FC</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">critic_input_shape</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">out_shape</span><span class="o">=</span><span class="n">critic_out_shape</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">PPO_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">max_mem_size</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">num_parallel_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> <span class="n">entropy_coeff</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">policy_nn</span><span class="o">=</span><span class="n">policy_nn</span><span class="p">,</span> <span class="n">critic_nn</span><span class="o">=</span><span class="n">critic_nn</span><span class="p">,</span> <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">tensorboard_dir</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">train_stats</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">train_n_steps</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">250000</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>)  Batch size for sampling from replay buffer.</p></li>
<li><p><strong>entropy_coeff</strong> (<em>float</em>)  Entropy regularization coefficient.</p></li>
<li><p><strong>num_epochs_per_update</strong> (<em>int</em>)  Training epochs per update.</p></li>
<li><p><strong>kl_div_thresh</strong> (<em>float</em>)  KL divergence threshold.</p></li>
<li><p><strong>clip_param</strong> (<em>float</em>)  Clipping parameter.</p></li>
<li><p><strong>experience_class</strong> (<a class="reference internal" href="#rlify.agents.agent_utils.ForgettingExperienceReplay" title="rlify.agents.agent_utils.ForgettingExperienceReplay"><em>ForgettingExperienceReplay</em></a>)  Experience replay class to use.</p></li>
<li><p><strong>explorer</strong> (<a class="reference internal" href="#rlify.agents.explorers.Explorer" title="rlify.agents.explorers.Explorer"><em>Explorer</em></a>)  Class for random exploration.</p></li>
<li><p><strong>kwArgs</strong>  Additional RL_Agent arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.set_train_mode">
<span class="sig-name descname"><span class="pre">set_train_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.set_train_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to train mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.set_eval_mode">
<span class="sig-name descname"><span class="pre">set_eval_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.set_eval_mode" title="Link to this definition"></a></dt>
<dd><p>sets the agent to train mode - all models are set to eval mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.get_models_input_output_shape">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Returns the input and output shapes of the Q model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.setup_models">
<span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Initializes the NN models</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.save_agent">
<span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.load_agent">
<span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.reset_rnn_hidden">
<span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>if agent uses rnn, when the hidden states are reset.
this callback is called in many places so please impliment it in you agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.set_num_parallel_env">
<span class="sig-name descname"><span class="pre">set_num_parallel_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_parallel_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.set_num_parallel_env" title="Link to this definition"></a></dt>
<dd><p>Sets the number of parallel environments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_parallel_envs</strong> (<em>int</em>)  number of parallel environments</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.best_act_discrete">
<span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.best_act_cont">
<span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent._get_ppo_experiences">
<span class="sig-name descname"><span class="pre">_get_ppo_experiences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">safe_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent._get_ppo_experiences" title="Link to this definition"></a></dt>
<dd><p>Current PPO only suports random_Samples = False!!</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.update_policy">
<span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>Update the policy network.
Args: exp (tuple): Experience tuple.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.ppo_agent'</span></em><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.ppo_agent.PPO_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.ppo_agent.PPO_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.heuristic_agent">
<span id="rlify-agents-heuristic-agent-module"></span><h2>rlify.agents.heuristic_agent module<a class="headerlink" href="#module-rlify.agents.heuristic_agent" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.heuristic_agent.</span></span><span class="sig-name descname"><span class="pre">Heuristic_Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heuristic_func</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.drl_agent.RL_Agent" title="rlify.agents.drl_agent.RL_Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">RL_Agent</span></code></a></p>
<p>A Heuristic Agent that uses a heuristic function to act.</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heuristic_func</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>heuristic_function</strong>  A function that takes in the inner_state, observation (ObsWraper) and returns a tuple: (inner_state, action) the inner state (could be None) and the action to be taken,
please notice that the actions shape is b,n_actions,action_dim
Please check more ObsWraper for  more info on the observation input object</p></li>
<li><p><strong>kwargs</strong>  Arguments for the RL_Agent base class</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">env_name</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env_c</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">heuristic_func</span><span class="p">(</span><span class="n">inner_state</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">ObsWraper</span><span class="p">):</span>
    <span class="c1"># an function that does not keep inner state</span>
    <span class="n">b_shape</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">b_shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># single discrete action</span>
    <span class="c1"># just a dummy heuristic for a gym env with np.array observations (for more details about the obs object check ObsWraper)</span>
    <span class="c1"># the heuristic check whether the first number of each observation is positive, if so, it returns action=1, else 0</span>
    <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">actions</span>

<span class="n">agent_c</span> <span class="o">=</span> <span class="n">Heuristic_Agent</span><span class="p">(</span><span class="n">obs_space</span><span class="o">=</span><span class="n">env_c</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env_c</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">heuristic_func</span><span class="o">=</span><span class="n">heuristic_func</span><span class="p">)</span>
<span class="n">reward</span> <span class="o">=</span> <span class="n">agent_c</span><span class="o">.</span><span class="n">run_env</span><span class="p">(</span><span class="n">env_c</span><span class="p">,</span> <span class="n">best_act</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Run Reward:&quot;</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.setup_models">
<span class="sig-name descname"><span class="pre">setup_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.setup_models" title="Link to this definition"></a></dt>
<dd><p>Does nothing in this agent.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.get_models_input_output_shape">
<span class="sig-name descname"><span class="pre">get_models_input_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.get_models_input_output_shape" title="Link to this definition"></a></dt>
<dd><p>Does nothing in this agent.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.save_agent">
<span class="sig-name descname"><span class="pre">save_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.save_agent" title="Link to this definition"></a></dt>
<dd><p>Saves the agent to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f_name</strong> (<em>str</em>)  file name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span></p>
</dd>
</dl>
<p>Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.load_agent">
<span class="sig-name descname"><span class="pre">load_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.load_agent" title="Link to this definition"></a></dt>
<dd><p>Loads the agent from a file.
Returns: a dictionary containing the agents state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.train" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The selected actions (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.best_act_discrete">
<span class="sig-name descname"><span class="pre">best_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.best_act_discrete" title="Link to this definition"></a></dt>
<dd><p>The best actions in a discrete action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.best_act_cont">
<span class="sig-name descname"><span class="pre">best_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.best_act_cont" title="Link to this definition"></a></dt>
<dd><p>The best actions in a continiuos action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong>  The observations to act on</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The highest probabilty action to be taken in a detrministic way</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.reset_rnn_hidden">
<span class="sig-name descname"><span class="pre">reset_rnn_hidden</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.reset_rnn_hidden" title="Link to this definition"></a></dt>
<dd><p>reset nn hidden_state - does nothing in this agent</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.update_policy">
<span class="sig-name descname"><span class="pre">update_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">exp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.update_policy" title="Link to this definition"></a></dt>
<dd><p>does nothing in this agent.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.get_last_collected_experiences">
<span class="sig-name descname"><span class="pre">get_last_collected_experiences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.get_last_collected_experiences" title="Link to this definition"></a></dt>
<dd><p>Mainly for Paired Algorithm support</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.clear_exp">
<span class="sig-name descname"><span class="pre">clear_exp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.clear_exp" title="Link to this definition"></a></dt>
<dd><p>clears the experience replay buffer</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({'set_eval_mode',</span> <span class="pre">'set_train_mode'})</span></em><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.heuristic_agent'</span></em><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.heuristic_agent.Heuristic_Agent._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.heuristic_agent.Heuristic_Agent._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.explorers">
<span id="rlify-agents-explorers-module"></span><h2>rlify.agents.explorers module<a class="headerlink" href="#module-rlify.agents.explorers" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.explorers.</span></span><span class="sig-name descname"><span class="pre">Explorer</span></span><a class="headerlink" href="#rlify.agents.explorers.Explorer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstrcat Exploration Class</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.Explorer.__init__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.explore">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">explore</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.Explorer.explore" title="Link to this definition"></a></dt>
<dd><p>Returns True if it is an exploration action time step</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.update">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.Explorer.update" title="Link to this definition"></a></dt>
<dd><p>updates the exploration epsilon</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.act">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.Explorer.act" title="Link to this definition"></a></dt>
<dd><p>Responsible for storing an inner state if needed(in self.inner_state attr)
Returns the action to be taken</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({'act',</span> <span class="pre">'explore',</span> <span class="pre">'update'})</span></em><a class="headerlink" href="#rlify.agents.explorers.Explorer.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.explorers.Explorer.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.explorers',</span> <span class="pre">'__doc__':</span> <span class="pre">'Abstrcat</span> <span class="pre">Exploration</span> <span class="pre">Class',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">Explorer.__init__&gt;,</span> <span class="pre">'explore':</span> <span class="pre">&lt;function</span> <span class="pre">Explorer.explore&gt;,</span> <span class="pre">'update':</span> <span class="pre">&lt;function</span> <span class="pre">Explorer.update&gt;,</span> <span class="pre">'act':</span> <span class="pre">&lt;function</span> <span class="pre">Explorer.act&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'Explorer'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'Explorer'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__abstractmethods__':</span> <span class="pre">frozenset({'explore',</span> <span class="pre">'update',</span> <span class="pre">'act'}),</span> <span class="pre">'_abc_impl':</span> <span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.explorers.Explorer.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.explorers'</span></em><a class="headerlink" href="#rlify.agents.explorers.Explorer.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.explorers.Explorer.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.Explorer._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.explorers.Explorer._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.explorers.</span></span><span class="sig-name descname"><span class="pre">RandomExplorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exploration_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_dec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.explorers.Explorer" title="rlify.agents.explorers.Explorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explorer</span></code></a></p>
<p>Class that acts a linear exploration method</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exploration_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_dec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exploration_epsilon</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The initial exploration epsilon</p></li>
<li><p><strong>eps_end</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>)  The final exploration epsilon</p></li>
<li><p><strong>eps_dec</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>)  The decay rate of the exploration epsilon</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.explore">
<span class="sig-name descname"><span class="pre">explore</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.explore" title="Link to this definition"></a></dt>
<dd><p>Returns True if it is an exploration action time step (randomness based on the exploration epsilon)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.update" title="Link to this definition"></a></dt>
<dd><p>updates the exploration epsilon in linear mode: exploration_epsilon * (1-self.eps_dec)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.act" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_space</strong>  The action space of the env</p></li>
<li><p><strong>obs</strong>  The observation of the env</p></li>
<li><p><strong>num_obs</strong>  The number of observations to act on</p></li>
</ul>
</dd>
</dl>
<p>Reutns a random action from the action space</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer._act_discrete">
<span class="sig-name descname"><span class="pre">_act_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer._act_discrete" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer._act_cont">
<span class="sig-name descname"><span class="pre">_act_cont</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer._act_cont" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.explorers'</span></em><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.RandomExplorer._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.explorers.RandomExplorer._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.explorers.</span></span><span class="sig-name descname"><span class="pre">HeuristicExplorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heuristic_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_dec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.explorers.RandomExplorer" title="rlify.agents.explorers.RandomExplorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomExplorer</span></code></a></p>
<p>A class for custom exploration methods- defined by user in init heuristic_function(inner_state, obs) - &gt; action</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heuristic_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_dec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>heuristic_function</strong>  A function that takes in the inner_state, observation (ObsWraper) and returns a tuple: (inner_state, action) the inner state (could be None) and the action to be taken,
please notice that the actions shape is b,n_actions,action_dim</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.explore">
<span class="sig-name descname"><span class="pre">explore</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.explore" title="Link to this definition"></a></dt>
<dd><p>Returns True if it is an exploration action time step (randomness based on the exploration epsilon)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.update" title="Link to this definition"></a></dt>
<dd><p>updates the exploration epsilon in linear mode: exploration_epsilon * (1-self.eps_dec)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.act">
<span class="sig-name descname"><span class="pre">act</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.act" title="Link to this definition"></a></dt>
<dd><p>Call the heuristic function to get the action, also updates the inner state</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.__abstractmethods__">
<span class="sig-name descname"><span class="pre">__abstractmethods__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">frozenset({})</span></em><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.__abstractmethods__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.explorers'</span></em><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.explorers.HeuristicExplorer._abc_impl">
<span class="sig-name descname"><span class="pre">_abc_impl</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;_abc._abc_data</span> <span class="pre">object&gt;</span></em><a class="headerlink" href="#rlify.agents.explorers.HeuristicExplorer._abc_impl" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.action_spaces_utils">
<span id="rlify-agents-action-spaces-utils-module"></span><h2>rlify.agents.action_spaces_utils module<a class="headerlink" href="#module-rlify.agents.action_spaces_utils" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.action_spaces_utils.</span></span><span class="sig-name descname"><span class="pre">MCAW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lows</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">highs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">locs_scales</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Multivariate Continuous Action Space wrapper</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lows</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">highs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">locs_scales</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>low</strong> (<em>list</em>)  the lower bound of the actions</p></li>
<li><p><strong>high</strong> (<em>list</em>)  the higher bound of the actions</p></li>
<li><p><strong>locs_scales</strong> (<em>torch.tensor</em>)  the mean and scale of all the actions</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.sample" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sample_shape</strong> (<em>torch.Size</em>)  the shape of the sample</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a tensor of shape (b, n_actions, sample_shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.log_prob" title="Link to this definition"></a></dt>
<dd><p>calculates the log prob of each action
:type actions: 
:param actions: a tensor of shape (b, n_actions)
:type actions: torch.tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>a tensor of shape (b, n_actions)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.loc">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loc</span></span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.loc" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.scale" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.entropy" title="Link to this definition"></a></dt>
<dd><p>caculates the mean entropy of all the actions
:returns: a tensor of shape (b, 1)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.action_spaces_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">Multivariate</span> <span class="pre">Continuous</span> <span class="pre">Action</span> <span class="pre">Space</span> <span class="pre">wrapper\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">MCAW.__init__&gt;,</span> <span class="pre">'sample':</span> <span class="pre">&lt;function</span> <span class="pre">MCAW.sample&gt;,</span> <span class="pre">'log_prob':</span> <span class="pre">&lt;function</span> <span class="pre">MCAW.log_prob&gt;,</span> <span class="pre">'loc':</span> <span class="pre">&lt;property</span> <span class="pre">object&gt;,</span> <span class="pre">'scale':</span> <span class="pre">&lt;property</span> <span class="pre">object&gt;,</span> <span class="pre">'entropy':</span> <span class="pre">&lt;function</span> <span class="pre">MCAW.entropy&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'MCAW'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'MCAW'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.action_spaces_utils'</span></em><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MCAW.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MCAW.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.CAW">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.action_spaces_utils.</span></span><span class="sig-name descname"><span class="pre">CAW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.CAW" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Normal</span></code></p>
<p>Continuous Action Wrapper</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.CAW.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.CAW.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>low</strong> (<em>float</em>)  the lower bound of the action</p></li>
<li><p><strong>high</strong> (<em>float</em>)  the higher bound of the action</p></li>
<li><p><strong>loc</strong> (<em>torch.tensor</em>)  the mean of the action</p></li>
<li><p><strong>scale</strong> (<em>torch.tensor</em>)  the scale of the action</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.CAW.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.CAW.sample" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sample_shape</strong> (<em>torch.Size</em>)  the shape of the sample</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a tensor of shape (b, sample_shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.CAW.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.action_spaces_utils'</span></em><a class="headerlink" href="#rlify.agents.action_spaces_utils.CAW.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.action_spaces_utils.</span></span><span class="sig-name descname"><span class="pre">MDA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">possible_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Multivariate Discrete Action Space</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">possible_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>np.array</em>)  an offset for start of each action</p></li>
<li><p><strong>possible_actions</strong> (<em>int</em>)  number of possible actions</p></li>
<li><p><strong>n_actions</strong> (<em>np.array</em>)  number of actions for each action</p></li>
<li><p><strong>x</strong> (<em>torch.tensor</em>)  the logits for each action</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.sample" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>a tensor of shape (b, n_actions, sample_shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.log_prob" title="Link to this definition"></a></dt>
<dd><p>calculates the log prob of each action
:type actions: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">tensor</span></code></span>
:param actions: a tensor of shape (b, n_actions)
:type actions: torch.tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>a tensor of shape (b, n_actions)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.probs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">probs</span></span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.probs" title="Link to this definition"></a></dt>
<dd><p>Returns:
a tensor of shape (b, n_actions)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.entropy" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.action_spaces_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">Multivariate</span> <span class="pre">Discrete</span> <span class="pre">Action</span> <span class="pre">Space\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">MDA.__init__&gt;,</span> <span class="pre">'sample':</span> <span class="pre">&lt;function</span> <span class="pre">MDA.sample&gt;,</span> <span class="pre">'log_prob':</span> <span class="pre">&lt;function</span> <span class="pre">MDA.log_prob&gt;,</span> <span class="pre">'probs':</span> <span class="pre">&lt;property</span> <span class="pre">object&gt;,</span> <span class="pre">'entropy':</span> <span class="pre">&lt;function</span> <span class="pre">MDA.entropy&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'MDA'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'MDA'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.action_spaces_utils'</span></em><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.action_spaces_utils.MDA.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.action_spaces_utils.MDA.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-rlify.agents.agent_utils">
<span id="rlify-agents-agent-utils-module"></span><h2>rlify.agents.agent_utils module<a class="headerlink" href="#module-rlify.agents.agent_utils" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.calc_gaes">
<span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">calc_gaes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rewards</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">terminated</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discount_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.calc_gaes" title="Link to this definition"></a></dt>
<dd><p>works with rewards vector which consitst of many epidsodes
Return the General Advantage Estimates from the given rewards and values.
Paper: <a class="reference external" href="https://arxiv.org/pdf/1506.02438.pdf">https://arxiv.org/pdf/1506.02438.pdf</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.calc_returns">
<span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">calc_returns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rewards</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">terminated</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discount_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.calc_returns" title="Link to this definition"></a></dt>
<dd><p>works with rewards vector which consitst of many epidsodes
Return the General Advantage Estimates from the given rewards and values.
Paper: <a class="reference external" href="https://arxiv.org/pdf/1506.02438.pdf">https://arxiv.org/pdf/1506.02438.pdf</a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ObsShapeWraper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper.dict_types">
<span class="sig-name descname"><span class="pre">dict_types</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'dict'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'gymnasium.spaces.dict.Dict'&gt;]</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper.dict_types" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper.__init__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'dict_types':</span> <span class="pre">[&lt;class</span> <span class="pre">'dict'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'gymnasium.spaces.dict.Dict'&gt;],</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsShapeWraper.__init__&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'ObsShapeWraper'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'ObsShapeWraper'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__doc__':</span> <span class="pre">None,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsShapeWraper.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.ObsShapeWraper.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ObsWraper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class for wrapping observations, the object is roughly a dict of np.arrays or torch.tensors
A default key is data for the main data if it in either a np.array or torch.tensor</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<span class="sphinx_autodoc_typehints-type">(<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">tensor</span></code>)</span>)  The data to wrap</p></li>
<li><p><strong>keep_dims</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>)  Whether to keep the dimensions of the data, if False will add a dimension of batch to the data</p></li>
<li><p><strong>tensors</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>)  Whether to keep the data in torch.tensor</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.update_shape">
<span class="sig-name descname"><span class="pre">update_shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.update_shape" title="Link to this definition"></a></dt>
<dd><p>Updates the shape of the object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.init_from_dict">
<span class="sig-name descname"><span class="pre">init_from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.init_from_dict" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.init_from_list_obsWrapper_obs">
<span class="sig-name descname"><span class="pre">init_from_list_obsWrapper_obs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_list</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.init_from_list_obsWrapper_obs" title="Link to this definition"></a></dt>
<dd><p>Initializes from a list of ObsWraper objects
:type obs_list: 
:param obs_list: The list of ObsWraper objects</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.init_from_list_generic_data">
<span class="sig-name descname"><span class="pre">init_from_list_generic_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_list</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.init_from_list_generic_data" title="Link to this definition"></a></dt>
<dd><p>Initializes from a list of generic data
:type obs_list: 
:param obs_list: The list of generic data</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper._init_from_none_">
<span class="sig-name descname"><span class="pre">_init_from_none_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper._init_from_none_" title="Link to this definition"></a></dt>
<dd><p>Initializes an object without data</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__setitem__">
<span class="sig-name descname"><span class="pre">__setitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__setitem__" title="Link to this definition"></a></dt>
<dd><p>Sets an item in the object
:type key: 
:param key: The key to set
:type value: 
:param value: The value to set</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__delitem__">
<span class="sig-name descname"><span class="pre">__delitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__delitem__" title="Link to this definition"></a></dt>
<dd><p>Deletes an item in the object</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>key</strong>  The key to delete</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__iter__">
<span class="sig-name descname"><span class="pre">__iter__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__iter__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>an iterator over the object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__getitem__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>key</strong>  The key to get</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The relevant item in respect to the key</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.slice_tensors">
<span class="sig-name descname"><span class="pre">slice_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.slice_tensors" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>key</strong>  The key to get</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sliced tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.keys">
<span class="sig-name descname"><span class="pre">keys</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.keys" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the keys of the object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.items">
<span class="sig-name descname"><span class="pre">items</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.items" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the items of the object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.values">
<span class="sig-name descname"><span class="pre">values</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.values" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the values of the object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__len__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The length of the object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__str__">
<span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__str__" title="Link to this definition"></a></dt>
<dd><p>Returns the string representation of the object</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__repr__" title="Link to this definition"></a></dt>
<dd><p>Return repr(self).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__mul__">
<span class="sig-name descname"><span class="pre">__mul__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__mul__" title="Link to this definition"></a></dt>
<dd><p>Multiplies the object by another object
:type other: 
:param other: The other object to multiply by
:param multiplies key by key using &lt;*&gt; pointwise operator:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__add__">
<span class="sig-name descname"><span class="pre">__add__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__add__" title="Link to this definition"></a></dt>
<dd><p>Adds the object by another object
:type other: 
:param other: The other object to add by
:param adds key by key using &lt;+&gt; pointwise operator:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__neg__">
<span class="sig-name descname"><span class="pre">__neg__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__neg__" title="Link to this definition"></a></dt>
<dd><p>Negates the object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__sub__">
<span class="sig-name descname"><span class="pre">__sub__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__sub__" title="Link to this definition"></a></dt>
<dd><p>Subtracts the object by another object
:type other: 
:param other: The other object to subtract by
:param subtracts key by key using &lt;-&gt; pointwise operator:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__truediv__">
<span class="sig-name descname"><span class="pre">__truediv__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__truediv__" title="Link to this definition"></a></dt>
<dd><p>Divides the object by another object
:type other: 
:param other: The other object to divide by
:param divides key by key using &lt;/&gt; pointwise operator:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.unsqueeze">
<span class="sig-name descname"><span class="pre">unsqueeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.unsqueeze" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dim</strong>  The device to put the tensors on</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The object as tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.squeeze">
<span class="sig-name descname"><span class="pre">squeeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.squeeze" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dim</strong>  The device to put the tensors on</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The object as tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.get_as_tensors">
<span class="sig-name descname"><span class="pre">get_as_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.get_as_tensors" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong>  The device to put the tensors on</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The object as tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.np_cat">
<span class="sig-name descname"><span class="pre">np_cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.np_cat" title="Link to this definition"></a></dt>
<dd><p>Concatenates the object by another object
:type other: 
:param other: The other object to concatenate by
:param concatenates key by key using np.concatenate:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The concatenated object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.np_append">
<span class="sig-name descname"><span class="pre">np_append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.np_append" title="Link to this definition"></a></dt>
<dd><p>Appends the object by another object
:type other: 
:param other: The other object to append by
:param appends key by key:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.cat">
<span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.cat" title="Link to this definition"></a></dt>
<dd><p>Concatenates the object by another object
:type other: 
:param other: The other object to concatenate by
:param concatenates key by key:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.np_zero_roll">
<span class="sig-name descname"><span class="pre">np_zero_roll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.np_zero_roll" title="Link to this definition"></a></dt>
<dd><p>Rolls the data by indx and fills the empty space with zeros - only on axis 0
:type indx: 
:param indx: The index to roll by
:type inplace: 
:param inplace: Whether to do the roll inplace</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The rolled object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.np_roll">
<span class="sig-name descname"><span class="pre">np_roll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.np_roll" title="Link to this definition"></a></dt>
<dd><p>Rolls the data by indx
:type indx: 
:param indx: The index to roll by
:type axis: 
:param axis: The axis to roll on
:type inplace: 
:param inplace: Whether to do the roll inplace</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The rolled object</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">&quot;\n</span>&#160;&#160;&#160; <span class="pre">A</span> <span class="pre">class</span> <span class="pre">for</span> <span class="pre">wrapping</span> <span class="pre">observations,</span> <span class="pre">the</span> <span class="pre">object</span> <span class="pre">is</span> <span class="pre">roughly</span> <span class="pre">a</span> <span class="pre">dict</span> <span class="pre">of</span> <span class="pre">np.arrays</span> <span class="pre">or</span> <span class="pre">torch.tensors\n</span>&#160;&#160;&#160; <span class="pre">A</span> <span class="pre">default</span> <span class="pre">key</span> <span class="pre">is</span> <span class="pre">'data'</span> <span class="pre">for</span> <span class="pre">the</span> <span class="pre">main</span> <span class="pre">data</span> <span class="pre">if</span> <span class="pre">it</span> <span class="pre">in</span> <span class="pre">either</span> <span class="pre">a</span> <span class="pre">np.array</span> <span class="pre">or</span> <span class="pre">torch.tensor\n</span>&#160;&#160;&#160; <span class="pre">&quot;,</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__init__&gt;,</span> <span class="pre">'update_shape':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.update_shape&gt;,</span> <span class="pre">'init_from_dict':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.init_from_dict&gt;,</span> <span class="pre">'init_from_list_obsWrapper_obs':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.init_from_list_obsWrapper_obs&gt;,</span> <span class="pre">'init_from_list_generic_data':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.init_from_list_generic_data&gt;,</span> <span class="pre">'_init_from_none_':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper._init_from_none_&gt;,</span> <span class="pre">'__setitem__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__setitem__&gt;,</span> <span class="pre">'__delitem__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__delitem__&gt;,</span> <span class="pre">'__iter__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__iter__&gt;,</span> <span class="pre">'__getitem__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__getitem__&gt;,</span> <span class="pre">'slice_tensors':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.slice_tensors&gt;,</span> <span class="pre">'keys':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.keys&gt;,</span> <span class="pre">'items':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.items&gt;,</span> <span class="pre">'values':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.values&gt;,</span> <span class="pre">'__len__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__len__&gt;,</span> <span class="pre">'__str__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__str__&gt;,</span> <span class="pre">'__repr__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__repr__&gt;,</span> <span class="pre">'__mul__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__mul__&gt;,</span> <span class="pre">'__add__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__add__&gt;,</span> <span class="pre">'__neg__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__neg__&gt;,</span> <span class="pre">'__sub__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__sub__&gt;,</span> <span class="pre">'__truediv__':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.__truediv__&gt;,</span> <span class="pre">'unsqueeze':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.unsqueeze&gt;,</span> <span class="pre">'squeeze':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.squeeze&gt;,</span> <span class="pre">'get_as_tensors':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.get_as_tensors&gt;,</span> <span class="pre">'np_cat':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.np_cat&gt;,</span> <span class="pre">'np_append':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.np_append&gt;,</span> <span class="pre">'cat':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.cat&gt;,</span> <span class="pre">'np_zero_roll':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.np_zero_roll&gt;,</span> <span class="pre">'np_roll':</span> <span class="pre">&lt;function</span> <span class="pre">ObsWraper.np_roll&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'ObsWraper'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'ObsWraper'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ObsWraper.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.ObsWraper.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ExperienceReplay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">capacity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prioritize_high_reward</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class for storing expriences and sampling from them</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">capacity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prioritize_high_reward</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>capacity</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>)  The max number of samples to store</p></li>
<li><p><strong>obs_shape</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></span>)  The shape of the obs</p></li>
<li><p><strong>n_actions</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of actions</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.__len__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current number of samples in the memory</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">curr_obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rewards</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncateds</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.append" title="Link to this definition"></a></dt>
<dd><p>Appends a new sample to the memory
:type curr_obs: <span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper" title="rlify.agents.agent_utils.ObsWraper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ObsWraper</span></code></a></span>
:param curr_obs: The current observations
:type actions: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param actions: The action taken
:type rewards: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param rewards: The reward recieved
:type dones: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param dones: Whether the episode is done</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.init_buffers">
<span class="sig-name descname"><span class="pre">init_buffers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.init_buffers" title="Link to this definition"></a></dt>
<dd><p>Initializes the buffers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.clear">
<span class="sig-name descname"><span class="pre">clear</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.clear" title="Link to this definition"></a></dt>
<dd><p>Clears the memory</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_episodes_accumulated_rewards">
<span class="sig-name descname"><span class="pre">get_episodes_accumulated_rewards</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_episodes_accumulated_rewards" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_episode_end_indices">
<span class="sig-name descname"><span class="pre">get_episode_end_indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_episode_end_indices" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_episode_start_indices">
<span class="sig-name descname"><span class="pre">get_episode_start_indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_episode_start_indices" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_first_episodes">
<span class="sig-name descname"><span class="pre">get_num_samples_of_k_first_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_first_episodes" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_last_episodes">
<span class="sig-name descname"><span class="pre">get_num_samples_of_k_last_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_last_episodes" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_last_episodes">
<span class="sig-name descname"><span class="pre">get_last_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_last_episodes" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_episodes</strong>  The number of episodes to return</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>all last episode samples, or specified num samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_first_episodes">
<span class="sig-name descname"><span class="pre">get_first_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_first_episodes" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_episodes</strong>  The number of episodes to return</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>all last episode samples, or specified num samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_first_samples">
<span class="sig-name descname"><span class="pre">get_first_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_first_samples" title="Link to this definition"></a></dt>
<dd><p>return all last episode samples, or specified num samples</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_last_samples">
<span class="sig-name descname"><span class="pre">get_last_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_last_samples" title="Link to this definition"></a></dt>
<dd><p>return all last episode samples, or specified num samples</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_all_buffers">
<span class="sig-name descname"><span class="pre">get_all_buffers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_all_buffers" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>All the buffers</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.get_buffers_at">
<span class="sig-name descname"><span class="pre">get_buffers_at</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.get_buffers_at" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong>  The indices to return</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The buffers at the given indices</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.sample_random_episodes">
<span class="sig-name descname"><span class="pre">sample_random_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.sample_random_episodes" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_episodes</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of full episodes to return</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A batch ofrandom episodes samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.sample_random_batch">
<span class="sig-name descname"><span class="pre">sample_random_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.sample_random_batch" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sample_size</strong>  The number of samples to return</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A random batch of samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">A</span> <span class="pre">class</span> <span class="pre">for</span> <span class="pre">storing</span> <span class="pre">expriences</span> <span class="pre">and</span> <span class="pre">sampling</span> <span class="pre">from</span> <span class="pre">them\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.__init__&gt;,</span> <span class="pre">'__len__':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.__len__&gt;,</span> <span class="pre">'append':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.append&gt;,</span> <span class="pre">'init_buffers':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.init_buffers&gt;,</span> <span class="pre">'clear':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.clear&gt;,</span> <span class="pre">'get_episodes_accumulated_rewards':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_episodes_accumulated_rewards&gt;,</span> <span class="pre">'get_episode_end_indices':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_episode_end_indices&gt;,</span> <span class="pre">'get_episode_start_indices':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_episode_start_indices&gt;,</span> <span class="pre">'get_num_samples_of_k_first_episodes':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_num_samples_of_k_first_episodes&gt;,</span> <span class="pre">'get_num_samples_of_k_last_episodes':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_num_samples_of_k_last_episodes&gt;,</span> <span class="pre">'get_last_episodes':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_last_episodes&gt;,</span> <span class="pre">'get_first_episodes':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_first_episodes&gt;,</span> <span class="pre">'get_first_samples':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_first_samples&gt;,</span> <span class="pre">'get_last_samples':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_last_samples&gt;,</span> <span class="pre">'get_all_buffers':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_all_buffers&gt;,</span> <span class="pre">'get_buffers_at':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.get_buffers_at&gt;,</span> <span class="pre">'sample_random_episodes':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.sample_random_episodes&gt;,</span> <span class="pre">'sample_random_batch':</span> <span class="pre">&lt;function</span> <span class="pre">ExperienceReplay.sample_random_batch&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'ExperienceReplay'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'ExperienceReplay'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ExperienceReplay.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.ExperienceReplay.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ForgettingExperienceReplay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">capacity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continous_mem</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#rlify.agents.agent_utils.ExperienceReplay" title="rlify.agents.agent_utils.ExperienceReplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExperienceReplay</span></code></a></p>
<p>This class is used to store and sample experience, it forgets old experience in every append.</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">capacity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continous_mem</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>capacity</strong>  The capacity of the replay buffer.</p></li>
<li><p><strong>obs_shape</strong>  The shape of the observations.</p></li>
<li><p><strong>continous_mem</strong>  If true, the replay buffer will be continous, meaning that the oldest samples will be overwritten.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.init_buffers">
<span class="sig-name descname"><span class="pre">init_buffers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.init_buffers" title="Link to this definition"></a></dt>
<dd><p>Initializes the buffers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">curr_obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rewards</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncateds</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.append" title="Link to this definition"></a></dt>
<dd><p>Appends a new sample to the memory.
:type curr_obs: <span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#rlify.agents.agent_utils.ObsWraper" title="rlify.agents.agent_utils.ObsWraper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ObsWraper</span></code></a></span>
:param curr_obs: The current observations.
:type actions: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param actions: The action taken.
:type rewards: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param rewards: The reward recieved.
:type dones: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">array</span></code></span>
:param dones: Whether the episode is done.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.get_last_episodes">
<span class="sig-name descname"><span class="pre">get_last_episodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.get_last_episodes" title="Link to this definition"></a></dt>
<dd><p>return all last episode samples, or specified num samples</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.__annotations__">
<span class="sig-name descname"><span class="pre">__annotations__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__annotations__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ForgettingExperienceReplay.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ForgettingExperienceReplay.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.worker">
<span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">worker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.worker" title="Link to this definition"></a></dt>
<dd><p>This function is used to run an environment in a separate process.
:type env: 
:param env: The environment to run.
:type conn: 
:param conn: The connection to the main process.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ParallelEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class is used to run multiple environments in parallel.</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Env</span></code></span>)  The environment to run in parallel.</p></li>
<li><p><strong>num_envs</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>)  The number of environments to run in parallel.</p></li>
<li><p><strong>for_val</strong>  If true, the environments will be run in a fixed order to allow for deterministic evaluation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.__del__">
<span class="sig-name descname"><span class="pre">__del__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.__del__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.change_env">
<span class="sig-name descname"><span class="pre">change_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.change_env" title="Link to this definition"></a></dt>
<dd><p>Changes the environment to run in parallel.
:type env: 
:param env: The new environment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.get_envs">
<span class="sig-name descname"><span class="pre">get_envs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.get_envs" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of the environments.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.reset" title="Link to this definition"></a></dt>
<dd><p>Resets the environments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.step" title="Link to this definition"></a></dt>
<dd><p>Takes a step in the environments.
:type actions: 
:param actions: The actions (n, action_shape) to take in the environments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.close_procs">
<span class="sig-name descname"><span class="pre">close_procs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.close_procs" title="Link to this definition"></a></dt>
<dd><p>Closes the processes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.render" title="Link to this definition"></a></dt>
<dd><p>Renders the environments. - not supported for multi envs - renders just the base env - good for single env case</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">This</span> <span class="pre">class</span> <span class="pre">is</span> <span class="pre">used</span> <span class="pre">to</span> <span class="pre">run</span> <span class="pre">multiple</span> <span class="pre">environments</span> <span class="pre">in</span> <span class="pre">parallel.\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.__init__&gt;,</span> <span class="pre">'__del__':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.__del__&gt;,</span> <span class="pre">'change_env':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.change_env&gt;,</span> <span class="pre">'get_envs':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.get_envs&gt;,</span> <span class="pre">'reset':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.reset&gt;,</span> <span class="pre">'step':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.step&gt;,</span> <span class="pre">'close_procs':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.close_procs&gt;,</span> <span class="pre">'render':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv.render&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'ParallelEnv'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'ParallelEnv'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">ParallelEnv_m</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong>  The environment to run in parallel.</p></li>
<li><p><strong>num_envs</strong>  The number of environments to run in parallel.</p></li>
<li><p><strong>for_val</strong>  If true, the environments will be run in a fixed order to allow for deterministic evaluation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.change_env">
<span class="sig-name descname"><span class="pre">change_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.change_env" title="Link to this definition"></a></dt>
<dd><p>Changes the environment to run in parallel.
:type env: 
:param env: The new environment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.get_envs">
<span class="sig-name descname"><span class="pre">get_envs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.get_envs" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of the environments.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.reset" title="Link to this definition"></a></dt>
<dd><p>Resets the environments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.step" title="Link to this definition"></a></dt>
<dd><p>Takes a step in the environments.
:type actions: 
:param actions: The actions (n, action_shape) to take in the environments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.render" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.__del__">
<span class="sig-name descname"><span class="pre">__del__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.__del__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.close_procs">
<span class="sig-name descname"><span class="pre">close_procs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.close_procs" title="Link to this definition"></a></dt>
<dd><p>Closes the processes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.__init__&gt;,</span> <span class="pre">'change_env':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.change_env&gt;,</span> <span class="pre">'get_envs':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.get_envs&gt;,</span> <span class="pre">'reset':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.reset&gt;,</span> <span class="pre">'step':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.step&gt;,</span> <span class="pre">'render':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.render&gt;,</span> <span class="pre">'__del__':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.__del__&gt;,</span> <span class="pre">'close_procs':</span> <span class="pre">&lt;function</span> <span class="pre">ParallelEnv_m.close_procs&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'ParallelEnv_m'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'ParallelEnv_m'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__doc__':</span> <span class="pre">None,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.ParallelEnv_m.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.ParallelEnv_m.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">SingleEnv_m</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class is used to run a single environment.</p>
<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env</strong>  The environment to run in parallel.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.change_env">
<span class="sig-name descname"><span class="pre">change_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.change_env" title="Link to this definition"></a></dt>
<dd><p>Changes the environment to run.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.get_envs">
<span class="sig-name descname"><span class="pre">get_envs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.get_envs" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of the environments - list with single item in this case.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.reset" title="Link to this definition"></a></dt>
<dd><p>Resets the environment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.step" title="Link to this definition"></a></dt>
<dd><p>Takes a step in the environment.
:type actions: 
:param actions: The actions (1, action_shape) to take in the environment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.render" title="Link to this definition"></a></dt>
<dd><p>Renders the environment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.close_procs">
<span class="sig-name descname"><span class="pre">close_procs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.close_procs" title="Link to this definition"></a></dt>
<dd><p>Closes the processes[actually is a noop in this case].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__doc__':</span> <span class="pre">'\n</span>&#160;&#160;&#160; <span class="pre">This</span> <span class="pre">class</span> <span class="pre">is</span> <span class="pre">used</span> <span class="pre">to</span> <span class="pre">run</span> <span class="pre">a</span> <span class="pre">single</span> <span class="pre">environment.\n</span>&#160;&#160;&#160; <span class="pre">',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.__init__&gt;,</span> <span class="pre">'change_env':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.change_env&gt;,</span> <span class="pre">'get_envs':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.get_envs&gt;,</span> <span class="pre">'reset':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.reset&gt;,</span> <span class="pre">'step':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.step&gt;,</span> <span class="pre">'render':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.render&gt;,</span> <span class="pre">'close_procs':</span> <span class="pre">&lt;function</span> <span class="pre">SingleEnv_m.close_procs&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'SingleEnv_m'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'SingleEnv_m'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.SingleEnv_m.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.SingleEnv_m.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlify.agents.agent_utils.</span></span><span class="sig-name descname"><span class="pre">TrainMetrics</span></span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__dict__">
<span class="sig-name descname"><span class="pre">__dict__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">mappingproxy({'__module__':</span> <span class="pre">'rlify.agents.agent_utils',</span> <span class="pre">'__init__':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.__init__&gt;,</span> <span class="pre">'add':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.add&gt;,</span> <span class="pre">'on_epoch_end':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.on_epoch_end&gt;,</span> <span class="pre">'get_metrcis_df':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.get_metrcis_df&gt;,</span> <span class="pre">'__iter__':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.__iter__&gt;,</span> <span class="pre">'__next__':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.__next__&gt;,</span> <span class="pre">'__getitem__':</span> <span class="pre">&lt;function</span> <span class="pre">TrainMetrics.__getitem__&gt;,</span> <span class="pre">'__dict__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__dict__'</span> <span class="pre">of</span> <span class="pre">'TrainMetrics'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__weakref__':</span> <span class="pre">&lt;attribute</span> <span class="pre">'__weakref__'</span> <span class="pre">of</span> <span class="pre">'TrainMetrics'</span> <span class="pre">objects&gt;,</span> <span class="pre">'__doc__':</span> <span class="pre">None,</span> <span class="pre">'__annotations__':</span> <span class="pre">{}})</span></em><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__dict__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__module__">
<span class="sig-name descname"><span class="pre">__module__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rlify.agents.agent_utils'</span></em><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__module__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__weakref__">
<span class="sig-name descname"><span class="pre">__weakref__</span></span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__weakref__" title="Link to this definition"></a></dt>
<dd><p>list of weak references to the object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>metrics</strong>  The metrics to store.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.add" title="Link to this definition"></a></dt>
<dd><p>Adds a metric to the metrics.
:type metric_name: 
:param metric_name: The name of the metric.
:type value: 
:param value: The value of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.on_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Adds a metric to the metrics.
:param metric_name: The name of the metric.
:param value: The value of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.get_metrcis_df">
<span class="sig-name descname"><span class="pre">get_metrcis_df</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.get_metrcis_df" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The metrics as a dataframe.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__iter__">
<span class="sig-name descname"><span class="pre">__iter__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__iter__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>An iterator over the metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__next__">
<span class="sig-name descname"><span class="pre">__next__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__next__" title="Link to this definition"></a></dt>
<dd><p>Returns:
An iterator over the metrics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlify.agents.agent_utils.TrainMetrics.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlify.agents.agent_utils.TrainMetrics.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Returns:
An iterator over the metrics.</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="readme_link.html" class="btn btn-neutral float-left" title="Welcome" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="rlify.models.html" class="btn btn-neutral float-right" title="rlify.models package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Nitsan Levy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>