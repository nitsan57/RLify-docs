Search.setIndex({"alltitles": {"Contents:": [[0, null]], "Contributions": [[1, "contributions"]], "Features": [[1, "features"]], "Indices and tables": [[0, "indices-and-tables"]], "License": [[1, "license"]], "RLify": [[1, "rlify"]], "Usage": [[1, "usage"]], "Welcome": [[1, "welcome"]], "Welcome to RLify\u2019s documentation!": [[0, "welcome-to-rlify-s-documentation"]], "Work in Progress": [[1, "work-in-progress"]], "rlify.agents package": [[2, "rlify-agents-package"]], "rlify.agents.action_spaces_utils module": [[2, "module-rlify.agents.action_spaces_utils"]], "rlify.agents.agent_utils module": [[2, "module-rlify.agents.agent_utils"]], "rlify.agents.ddpg_agent module": [[2, "module-rlify.agents.ddpg_agent"]], "rlify.agents.dqn_agent module": [[2, "module-rlify.agents.dqn_agent"]], "rlify.agents.drl_agent module": [[2, "module-rlify.agents.drl_agent"]], "rlify.agents.explorers module": [[2, "module-rlify.agents.explorers"]], "rlify.agents.heuristic_agent module": [[2, "module-rlify.agents.heuristic_agent"]], "rlify.agents.ppo_agent module": [[2, "module-rlify.agents.ppo_agent"]], "rlify.agents.vdqn_agent module": [[2, "module-rlify.agents.vdqn_agent"]], "rlify.models package": [[3, "rlify-models-package"]], "rlify.models.base_model module": [[3, "module-rlify.models.base_model"]], "rlify.models.fc module": [[3, "module-rlify.models.fc"]], "rlify.models.model_factory module": [[3, "module-rlify.models.model_factory"]], "rlify.models.rnn module": [[3, "module-rlify.models.rnn"]]}, "docnames": ["index", "readme_link", "rlify.agents", "rlify.models"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.rst", "readme_link.rst", "rlify.agents.rst", "rlify.models.rst"], "indexentries": {"__abstractmethods__ (rlify.models.base_model.basemodel attribute)": [[3, "rlify.models.base_model.BaseModel.__abstractmethods__", false]], "__abstractmethods__ (rlify.models.fc.fc attribute)": [[3, "rlify.models.fc.FC.__abstractmethods__", false]], "__abstractmethods__ (rlify.models.rnn.gru attribute)": [[3, "rlify.models.rnn.GRU.__abstractmethods__", false]], "__abstractmethods__ (rlify.models.rnn.reccurentlayer attribute)": [[3, "rlify.models.rnn.ReccurentLayer.__abstractmethods__", false]], "__annotations__ (rlify.models.base_model.basemodel attribute)": [[3, "rlify.models.base_model.BaseModel.__annotations__", false]], "__annotations__ (rlify.models.fc.fc attribute)": [[3, "rlify.models.fc.FC.__annotations__", false]], "__annotations__ (rlify.models.rnn.gru attribute)": [[3, "rlify.models.rnn.GRU.__annotations__", false]], "__annotations__ (rlify.models.rnn.reccurentlayer attribute)": [[3, "rlify.models.rnn.ReccurentLayer.__annotations__", false]], "__init__() (rlify.models.base_model.basemodel method)": [[3, "rlify.models.base_model.BaseModel.__init__", false]], "__init__() (rlify.models.fc.fc method)": [[3, "rlify.models.fc.FC.__init__", false]], "__init__() (rlify.models.rnn.gru method)": [[3, "rlify.models.rnn.GRU.__init__", false]], "__init__() (rlify.models.rnn.reccurentlayer method)": [[3, "rlify.models.rnn.ReccurentLayer.__init__", false]], "__init_subclass__() (rlify.models.base_model.basemodel class method)": [[3, "rlify.models.base_model.BaseModel.__init_subclass__", false]], "__module__ (rlify.models.base_model.basemodel attribute)": [[3, "rlify.models.base_model.BaseModel.__module__", false]], "__module__ (rlify.models.fc.fc attribute)": [[3, "rlify.models.fc.FC.__module__", false]], "__module__ (rlify.models.rnn.gru attribute)": [[3, "rlify.models.rnn.GRU.__module__", false]], "__module__ (rlify.models.rnn.reccurentlayer attribute)": [[3, "rlify.models.rnn.ReccurentLayer.__module__", false]], "_abc_impl (rlify.models.base_model.basemodel attribute)": [[3, "rlify.models.base_model.BaseModel._abc_impl", false]], "_abc_impl (rlify.models.fc.fc attribute)": [[3, "rlify.models.fc.FC._abc_impl", false]], "_abc_impl (rlify.models.rnn.gru attribute)": [[3, "rlify.models.rnn.GRU._abc_impl", false]], "_abc_impl (rlify.models.rnn.reccurentlayer attribute)": [[3, "rlify.models.rnn.ReccurentLayer._abc_impl", false]], "basemodel (class in rlify.models.base_model)": [[3, "rlify.models.base_model.BaseModel", false]], "device (rlify.models.base_model.basemodel property)": [[3, "rlify.models.base_model.BaseModel.device", false]], "fc (class in rlify.models.fc)": [[3, "rlify.models.fc.FC", false]], "forward() (rlify.models.base_model.basemodel method)": [[3, "rlify.models.base_model.BaseModel.forward", false]], "forward() (rlify.models.fc.fc method)": [[3, "rlify.models.fc.FC.forward", false]], "forward() (rlify.models.rnn.gru method)": [[3, "rlify.models.rnn.GRU.forward", false]], "forward() (rlify.models.rnn.reccurentlayer method)": [[3, "rlify.models.rnn.ReccurentLayer.forward", false]], "get_model_class() (in module rlify.models.model_factory)": [[3, "rlify.models.model_factory.get_model_class", false]], "get_seqs_indices_for_pack() (in module rlify.models.rnn)": [[3, "rlify.models.rnn.get_seqs_indices_for_pack", false]], "get_total_params() (rlify.models.base_model.basemodel method)": [[3, "rlify.models.base_model.BaseModel.get_total_params", false]], "gru (class in rlify.models.rnn)": [[3, "rlify.models.rnn.GRU", false]], "is_rnn (rlify.models.base_model.basemodel attribute)": [[3, "rlify.models.base_model.BaseModel.is_rnn", false]], "is_rnn (rlify.models.rnn.reccurentlayer attribute)": [[3, "rlify.models.rnn.ReccurentLayer.is_rnn", false]], "module": [[3, "module-rlify.models.base_model", false], [3, "module-rlify.models.fc", false], [3, "module-rlify.models.model_factory", false], [3, "module-rlify.models.rnn", false]], "pack_from_done_indices() (in module rlify.models.rnn)": [[3, "rlify.models.rnn.pack_from_done_indices", false]], "reccurentlayer (class in rlify.models.rnn)": [[3, "rlify.models.rnn.ReccurentLayer", false]], "reset() (rlify.models.base_model.basemodel method)": [[3, "rlify.models.base_model.BaseModel.reset", false]], "reset() (rlify.models.fc.fc method)": [[3, "rlify.models.fc.FC.reset", false]], "reset() (rlify.models.rnn.gru method)": [[3, "rlify.models.rnn.GRU.reset", false]], "reset() (rlify.models.rnn.reccurentlayer method)": [[3, "rlify.models.rnn.ReccurentLayer.reset", false]], "rlify.models.base_model": [[3, "module-rlify.models.base_model", false]], "rlify.models.fc": [[3, "module-rlify.models.fc", false]], "rlify.models.model_factory": [[3, "module-rlify.models.model_factory", false]], "rlify.models.rnn": [[3, "module-rlify.models.rnn", false]]}, "objects": {"rlify.agents": [[2, 0, 0, "-", "action_spaces_utils"], [2, 0, 0, "-", "agent_utils"], [2, 0, 0, "-", "ddpg_agent"], [2, 0, 0, "-", "dqn_agent"], [2, 0, 0, "-", "drl_agent"], [2, 0, 0, "-", "explorers"], [2, 0, 0, "-", "heuristic_agent"], [2, 0, 0, "-", "ppo_agent"], [2, 0, 0, "-", "vdqn_agent"]], "rlify.agents.action_spaces_utils": [[2, 1, 1, "", "CAW"], [2, 1, 1, "", "MCAW"], [2, 1, 1, "", "MDA"]], "rlify.agents.action_spaces_utils.CAW": [[2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "sample"]], "rlify.agents.action_spaces_utils.MCAW": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 4, 1, "", "loc"], [2, 2, 1, "", "log_prob"], [2, 2, 1, "", "sample"], [2, 4, 1, "", "scale"]], "rlify.agents.action_spaces_utils.MDA": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 2, 1, "", "log_prob"], [2, 4, 1, "", "probs"], [2, 2, 1, "", "sample"]], "rlify.agents.agent_utils": [[2, 1, 1, "", "ExperienceReplay"], [2, 1, 1, "", "ForgettingExperienceReplay"], [2, 1, 1, "", "ObsShapeWraper"], [2, 1, 1, "", "ObsWraper"], [2, 1, 1, "", "ParallelEnv"], [2, 1, 1, "", "ParallelEnv_m"], [2, 1, 1, "", "SingleEnv_m"], [2, 1, 1, "", "TrainMetrics"], [2, 5, 1, "", "calc_gaes"], [2, 5, 1, "", "calc_returns"], [2, 5, 1, "", "worker"]], "rlify.agents.agent_utils.ExperienceReplay": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "clear"], [2, 2, 1, "", "get_all_buffers"], [2, 2, 1, "", "get_buffers_at"], [2, 2, 1, "", "get_episode_end_indices"], [2, 2, 1, "", "get_episode_start_indices"], [2, 2, 1, "", "get_episodes_accumulated_rewards"], [2, 2, 1, "", "get_first_episodes"], [2, 2, 1, "", "get_first_samples"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "get_last_samples"], [2, 2, 1, "", "get_num_samples_of_k_first_episodes"], [2, 2, 1, "", "get_num_samples_of_k_last_episodes"], [2, 2, 1, "", "init_buffers"], [2, 2, 1, "", "sample_random_batch"], [2, 2, 1, "", "sample_random_episodes"]], "rlify.agents.agent_utils.ForgettingExperienceReplay": [[2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "init_buffers"]], "rlify.agents.agent_utils.ObsShapeWraper": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "dict_types"]], "rlify.agents.agent_utils.ObsWraper": [[2, 2, 1, "", "__add__"], [2, 2, 1, "", "__delitem__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__getitem__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__iter__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "__mul__"], [2, 2, 1, "", "__neg__"], [2, 2, 1, "", "__repr__"], [2, 2, 1, "", "__setitem__"], [2, 2, 1, "", "__str__"], [2, 2, 1, "", "__sub__"], [2, 2, 1, "", "__truediv__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "_init_from_none_"], [2, 2, 1, "", "cat"], [2, 2, 1, "", "get_as_tensors"], [2, 2, 1, "", "init_from_dict"], [2, 2, 1, "", "init_from_list_generic_data"], [2, 2, 1, "", "init_from_list_obsWrapper_obs"], [2, 2, 1, "", "items"], [2, 2, 1, "", "keys"], [2, 2, 1, "", "np_append"], [2, 2, 1, "", "np_cat"], [2, 2, 1, "", "np_roll"], [2, 2, 1, "", "np_zero_roll"], [2, 2, 1, "", "slice_tensors"], [2, 2, 1, "", "squeeze"], [2, 2, 1, "", "unsqueeze"], [2, 2, 1, "", "update_shape"], [2, 2, 1, "", "values"]], "rlify.agents.agent_utils.ParallelEnv": [[2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.ParallelEnv_m": [[2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.SingleEnv_m": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.TrainMetrics": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__getitem__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__iter__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "__next__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "add"], [2, 2, 1, "", "get_metrcis_df"], [2, 2, 1, "", "on_epoch_end"]], "rlify.agents.ddpg_agent": [[2, 1, 1, "", "DDPG_Agent"]], "rlify.agents.ddpg_agent.DDPG_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "actor_action"], [2, 2, 1, "", "best_act"], [2, 2, 1, "", "check_action_space"], [2, 2, 1, "", "get_actor_action_value"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "hard_target_update"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "soft_target_update"], [2, 2, 1, "", "update_policy"]], "rlify.agents.dqn_agent": [[2, 1, 1, "", "DQN_Agent"]], "rlify.agents.dqn_agent.DQN_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "hard_target_update"], [2, 2, 1, "", "init_target_update_rule"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "soft_target_update"], [2, 2, 1, "", "update_policy"]], "rlify.agents.drl_agent": [[2, 1, 1, "", "RL_Agent"]], "rlify.agents.drl_agent.RL_Agent": [[2, 3, 1, "", "EVAL"], [2, 3, 1, "", "TRAIN"], [2, 3, 1, "", "__abstractmethods__"], [2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_train_n_iters"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "close_env_procs"], [2, 2, 1, "", "collect_episode_obs"], [2, 2, 1, "", "define_action_space"], [2, 2, 1, "", "get_highest_score_agent_ckpt_path"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "get_train_metrics"], [2, 2, 1, "", "init_tb_writer"], [2, 2, 1, "", "intrisic_reward_func"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "load_highest_score_agent"], [2, 2, 1, "", "norm_obs"], [2, 2, 1, "", "pre_process_obs_for_act"], [2, 2, 1, "", "read_action_space_properties"], [2, 2, 1, "", "read_obs_space_properties"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "return_correct_actions_dim"], [2, 2, 1, "", "run_env"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_intrisic_reward_func"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "train_episodial"], [2, 2, 1, "", "train_n_steps"], [2, 2, 1, "", "update_policy"]], "rlify.agents.explorers": [[2, 1, 1, "", "Explorer"], [2, 1, 1, "", "HeuristicExplorer"], [2, 1, 1, "", "RandomExplorer"]], "rlify.agents.explorers.Explorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.explorers.HeuristicExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.explorers.RandomExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_act_cont"], [2, 2, 1, "", "_act_discrete"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.heuristic_agent": [[2, 1, 1, "", "Heuristic_Agent"]], "rlify.agents.heuristic_agent.Heuristic_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "train"], [2, 2, 1, "", "update_policy"]], "rlify.agents.ppo_agent": [[2, 1, 1, "", "PPO_Agent"]], "rlify.agents.ppo_agent.PPO_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_ppo_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "update_policy"]], "rlify.agents.vdqn_agent": [[2, 1, 1, "", "VDQN_Agent"]], "rlify.agents.vdqn_agent.VDQN_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_dqn_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "act_base"], [2, 2, 1, "", "best_act"], [2, 2, 1, "", "check_action_space"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "update_policy"]], "rlify.models": [[3, 0, 0, "-", "base_model"], [3, 0, 0, "-", "fc"], [3, 0, 0, "-", "model_factory"], [3, 0, 0, "-", "rnn"]], "rlify.models.base_model": [[3, 1, 1, "", "BaseModel"]], "rlify.models.base_model.BaseModel": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 2, 1, "", "__init_subclass__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 4, 1, "", "device"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "get_total_params"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]], "rlify.models.fc": [[3, 1, 1, "", "FC"]], "rlify.models.fc.FC": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlify.models.model_factory": [[3, 5, 1, "", "get_model_class"]], "rlify.models.rnn": [[3, 1, 1, "", "GRU"], [3, 1, 1, "", "ReccurentLayer"], [3, 5, 1, "", "get_seqs_indices_for_pack"], [3, 5, 1, "", "pack_from_done_indices"]], "rlify.models.rnn.GRU": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlify.models.rnn.ReccurentLayer": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "terms": {"": [1, 2], "0": 2, "0001": 2, "0003": 2, "01": 2, "02438": 2, "03": 2, "05": 2, "0x7f23dd9957c0": [], "0x7f252f1957c0": [], "0x7f6dcff957c0": [], "0x7f73bf3957c0": [], "0x7f8108b957c0": [], "0x7f8c6e7957c0": [], "0x7f9d827957c0": [], "0x7fc2ed5957c0": [], "0x7fce1d7957c0": [], "1": 2, "10": 2, "100000": [], "10000000": 2, "1024": 2, "10e6": 2, "128": 2, "1506": 2, "16": 2, "2": [2, 3], "250000": 2, "256": 2, "3": 2, "350000": [], "3e": 2, "4": 2, "5": 2, "64": [2, 3], "80000": 2, "9": 2, "99": 2, "A": [1, 2, 3], "And": 1, "For": 1, "If": [1, 2], "It": [1, 2, 3], "No": 1, "The": [2, 3], "__abstractmethods__": [2, 3], "__add__": 2, "__annotations__": [2, 3], "__call__": 3, "__del__": 2, "__delitem__": 2, "__dict__": 2, "__doc__": 2, "__getitem__": 2, "__init__": [2, 3], "__init_subclass__": 3, "__iter__": 2, "__len__": 2, "__module__": [2, 3], "__mul__": 2, "__neg__": 2, "__next__": 2, "__repr__": 2, "__setitem__": 2, "__str__": 2, "__sub__": 2, "__truediv__": 2, "__weakref__": 2, "_abc": [2, 3], "_abc_data": [2, 3], "_abc_impl": [2, 3], "_act_cont": 2, "_act_discret": 2, "_backward_hook": 3, "_backward_pre_hook": 3, "_buffer": 3, "_compiled_call_impl": 3, "_forward_hook": 3, "_forward_hooks_always_cal": 3, "_forward_hooks_with_kwarg": 3, "_forward_pre_hook": 3, "_forward_pre_hooks_with_kwarg": 3, "_get_dqn_experi": 2, "_get_ppo_experi": 2, "_init_from_none_": 2, "_is_full_backward_hook": 3, "_load_state_dict_post_hook": 3, "_load_state_dict_pre_hook": 3, "_modul": 3, "_non_persistent_buffers_set": 3, "_paramet": 3, "_state_dict_hook": 3, "_state_dict_pre_hook": 3, "_train_n_it": 2, "_version": 3, "abc": [2, 3], "about": 2, "absolut": 2, "abstract": [2, 3], "abstrcat": 2, "accord": 2, "act": 2, "act_bas": 2, "action": [1, 2], "action_dim": 2, "action_shap": 2, "action_spac": 2, "action_spaces_util": 0, "activ": [2, 3], "actor": 2, "actor_act": 2, "actual": 2, "ad": 1, "add": [1, 2], "addit": 2, "advantag": 2, "after": 2, "agent": [0, 1], "agent_c": 2, "agent_util": 0, "agnet": 2, "algorithm": [1, 2], "all": [1, 2, 3], "allow": 2, "also": [1, 2], "an": [1, 2], "ani": 3, "anoth": 2, "api": [1, 2], "append": 2, "ar": 2, "architectur": 1, "arg": [2, 3], "argument": 2, "arrai": 2, "arxiv": 2, "attr": 2, "attribut": 2, "availbl": 2, "axi": 2, "b": 2, "b_shape": 2, "base": [2, 3], "base_model": 0, "basemodel": [2, 3], "basic": [2, 3], "batch": 2, "batch_siz": 2, "best": 2, "best_act": 2, "best_act_cont": 2, "best_act_discret": 2, "bool": [2, 3], "bound": 2, "buffer": 2, "bug": 1, "built": 2, "cacul": 2, "calc_ga": 2, "calc_return": 2, "calcul": [2, 3], "call": [2, 3], "call_super_init": 3, "callabl": 3, "callback": [1, 2], "can": [1, 3], "capac": 2, "cartpol": 2, "case": 2, "cat": 2, "caw": 2, "certain": 1, "certein": 1, "chang": 2, "change_env": 2, "check": [1, 2], "check_action_spac": 2, "choic": 1, "class": [2, 3], "classmethod": 3, "clear": 2, "clear_exp": 2, "clip": 2, "clip_param": 2, "clipe": 1, "clone": 1, "close": 2, "close_env_proc": 2, "close_proc": 2, "coeffici": 2, "collect": 2, "collect_episode_ob": 2, "compat": 1, "concaten": 2, "conn": 2, "connect": [2, 3], "consitst": 2, "contain": 2, "contin": 2, "continiuo": [], "continous_mem": 2, "continu": [1, 2], "correct": 2, "could": 2, "cpu": 2, "creat": [1, 2], "critic_input_shap": 2, "critic_nn": 2, "critic_out_shap": 2, "curr": 1, "curr_ob": 2, "current": 2, "custom": 2, "customiz": 1, "d": 3, "data": [2, 3], "datafram": 2, "ddpg": [1, 2], "ddpg_agent": 0, "ddqn": 1, "decai": 2, "deep": [], "def": 2, "default": [2, 3], "defin": 2, "define_action_spac": 2, "delet": 2, "deploy": 1, "depth": [2, 3], "design": 1, "destructor": 2, "detail": 2, "determinist": 2, "detrminist": 2, "detrminst": 2, "develop": 1, "devic": [2, 3], "dict": [2, 3], "dict_typ": 2, "dictionari": [1, 2], "dim": 2, "dimens": [2, 3], "diment": 2, "directori": 2, "disabl": 2, "disable_tqdm": 2, "discount": 2, "discount_factor": 2, "discret": [1, 2], "diverg": 2, "divid": 2, "do": 2, "doc": 1, "doe": [2, 3], "done": [2, 3], "done_indic": 3, "dq_reg": [], "dqn": [1, 2], "dqn_agent": 0, "dqn_reg": 2, "drl_agent": 0, "dummi": 2, "dummy_reward_func": 2, "dump": 1, "dump_patch": 3, "each": 2, "either": [1, 2], "els": 2, "embed": 3, "embed_dim": [2, 3], "empti": 2, "enhanc": 1, "entropi": 2, "entropy_coeff": 2, "env": [1, 2], "env_c": 2, "env_func": 2, "env_nam": 2, "environ": [1, 2], "epidsod": 2, "episod": 2, "epoch": 2, "eps_dec": 2, "eps_end": 2, "epsilon": 2, "estim": 2, "eval": 2, "evalu": 2, "everi": 2, "exampl": [1, 2], "exp": 2, "experi": 2, "experience_class": 2, "experiencereplai": 2, "exploit": 2, "explor": [0, 1], "exploration_epsilon": 2, "exprienc": 2, "extend": [1, 3], "extren": 1, "f_name": 2, "facilit": 1, "factor": 2, "fals": [2, 3], "fc": [0, 2], "feel": 1, "file": 2, "fill": 2, "final": 2, "first": 2, "fix": [1, 2], "flexibl": 1, "float": 2, "follow": [], "for_val": 2, "forc": 2, "forget": 2, "forgettingexperiencereplai": 2, "format": 1, "forward": 3, "framework": 1, "free": 1, "from": [1, 2, 3], "frozenset": [2, 3], "full": 2, "fulli": [1, 3], "func": 2, "function": [1, 2, 3], "futur": 2, "gener": 2, "get": [1, 2], "get_action_valu": [], "get_actor_action_valu": 2, "get_all_buff": 2, "get_as_tensor": 2, "get_buffers_at": 2, "get_env": 2, "get_episode_end_indic": 2, "get_episode_start_indic": 2, "get_episodes_accumulated_reward": 2, "get_first_episod": 2, "get_first_sampl": 2, "get_highest_score_agent_ckpt_path": 2, "get_last_collected_experi": 2, "get_last_episod": 2, "get_last_sampl": 2, "get_metrcis_df": 2, "get_model_class": 3, "get_models_input_output_shap": 2, "get_num_samples_of_k_first_episod": 2, "get_num_samples_of_k_last_episod": 2, "get_seqs_indices_for_pack": 3, "get_total_param": 3, "get_train_metr": 2, "given": 2, "good": 2, "gru": 3, "gym": [1, 2], "gymnasium": 2, "hard": 2, "hard_target_upd": 2, "helper": 2, "heurist": [1, 2], "heuristic_ag": 0, "heuristic_func": 2, "heuristic_funct": 2, "heuristicexplor": [1, 2], "heurstic": 1, "hidden": [2, 3], "hidden_dim": 3, "hidden_st": 2, "high": 2, "higher": 2, "highest": 2, "http": 2, "human": 1, "i": [1, 2, 3], "implement": [1, 3], "impliment": 2, "includ": 1, "index": [0, 2], "indic": [2, 3], "indx": 2, "info": 2, "inherit": [1, 2], "init": 2, "init_buff": 2, "init_from_dict": 2, "init_from_list_generic_data": 2, "init_from_list_obswrapper_ob": 2, "init_target_update_rul": 2, "init_tb_writ": 2, "initi": 2, "inner": 2, "inner_st": 2, "inplac": 2, "input": [1, 2, 3], "input_shap": [2, 3], "int": [2, 3], "integr": 1, "interest": 1, "intrins": 1, "intrisic_reward_func": 2, "ipynb": 1, "is_rnn": 3, "issu": 1, "item": 2, "iter": 2, "just": [2, 3], "keep": 2, "keep_dim": 2, "kei": 2, "kl": 2, "kl_div_thresh": 2, "kwarg": [2, 3], "l2": 2, "last": 2, "leakyrelu": [], "learn": [1, 2], "len": 2, "length": 2, "linear": 2, "list": 2, "load": 2, "load_ag": 2, "load_highest_score_ag": 2, "loc": 2, "locs_scal": 2, "log": 2, "log_prob": 2, "logic": [1, 2], "logit": 2, "low": 2, "lower": 2, "lr": 2, "lunarland": [], "mai": 3, "main": 2, "mainli": 2, "make": 2, "mani": [1, 2], "manual_upd": 2, "map": 2, "mappingproxi": 2, "marl": 1, "max": 2, "max_episode_len": 2, "max_mem_s": 2, "maximum": 2, "mcaw": 2, "mda": 2, "mean": 2, "memori": 2, "method": [1, 2, 3], "metric": [1, 2], "metric_nam": 2, "mit": 1, "mle": 2, "mode": 2, "model": [0, 1, 2], "model_factori": 0, "model_typ": 3, "models_shap": 2, "modul": 0, "more": [1, 2], "multi": 2, "multipl": 2, "multipli": 2, "multivari": 2, "n": 2, "n_action": 2, "n_episod": 2, "n_iter": 2, "n_step": 2, "name": 2, "ndarrai": 2, "need": 2, "negat": 2, "negative_slop": [], "network": [1, 2], "neural": 1, "new": [1, 2], "next_stat": 2, "nn": [2, 3], "none": [2, 3], "noop": 2, "norm_ob": 2, "normal": 2, "normali": 2, "noth": [2, 3], "notic": 2, "now": 2, "np": 2, "np_append": 2, "np_cat": 2, "np_roll": 2, "np_zero_rol": 2, "num": 2, "num_env": 2, "num_episod": 2, "num_epochs_per_upd": 2, "num_gru": 3, "num_ob": 2, "num_parallel_env": 2, "num_run": 2, "num_sampl": 2, "num_to_collect_in_parallel": 2, "number": [2, 3], "number_of_episod": 2, "ob": 2, "object": [2, 3], "obs_list": 2, "obs_shap": 2, "obs_spac": 2, "observ": [1, 2], "observation_spac": 2, "obsshapewrap": 2, "obswrap": 2, "offset": 2, "ofrandom": 2, "old": 2, "oldest": 2, "on_epoch_end": 2, "onli": 2, "open": 1, "openai": 1, "oper": 2, "optim": 2, "option": [2, 3], "order": 2, "org": 2, "other": 2, "out_shap": [2, 3], "output": [2, 3], "over": 2, "overrid": 1, "overridden": 3, "overwritten": 2, "own": 1, "pack": 3, "pack_from_done_indic": 3, "packag": 0, "packedsequ": 3, "page": 0, "pair": 2, "paper": 2, "parallel": 2, "parallelenv": 2, "parallelenv_m": 2, "param": 2, "paramet": [2, 3], "pass": 3, "path": 2, "pdf": 2, "pendulum": 2, "per": 2, "place": 2, "pleas": [1, 2], "pointwis": 2, "polici": 2, "policy_input_shap": 2, "policy_nn": 2, "policy_out_shap": 2, "posit": 2, "possibl": 2, "possible_act": 2, "ppo": [1, 2], "ppo_ag": 0, "pre": 2, "pre_process_obs_for_act": 2, "print": 2, "prioritize_high_reward": 2, "prob": 2, "probabilti": 2, "probabl": 2, "process": 2, "properti": [2, 3], "provid": 1, "proxim": 2, "pull": 1, "put": 2, "pytorch": 1, "q": 2, "q_input_shap": 2, "q_mle_input_shap": 2, "q_mle_model": 2, "q_mle_out_shap": 2, "q_model": 2, "q_out_shap": 2, "random": [1, 2], "random_sampl": 2, "randomexplor": 2, "rate": 2, "re": 1, "read_action_space_properti": 2, "read_obs_space_properti": 2, "reccurentlay": 3, "reciev": 2, "recurr": 1, "refer": 2, "regular": 2, "reinforc": [1, 2], "relev": 2, "relu": [2, 3], "render": 2, "render_mod": 2, "replai": 2, "repo": 1, "repr": 2, "represent": 2, "request": 1, "reset": [2, 3], "reset_rnn_hidden": 2, "respect": 2, "respons": 2, "return": [2, 3], "return_correct_actions_dim": 2, "reutn": 2, "reward": [1, 2], "reward_norm": 2, "rich": 1, "right": 2, "rl": [1, 2], "rl_agent": 2, "rnn": [0, 2], "robust": 1, "roll": 2, "roughli": 2, "rule": 2, "run": 2, "run_env": 2, "safe_check": 2, "sampl": 2, "sample_random_batch": 2, "sample_random_episod": 2, "sample_s": 2, "sample_shap": 2, "save": [1, 2], "save_ag": 2, "scale": 2, "score": 2, "seamlessli": 1, "search": 0, "select": 2, "self": 2, "separ": 2, "seq_len": 3, "sequenc": 3, "set": [1, 2, 3], "set_eval_mod": 2, "set_intrinsic_reward_func": 1, "set_intrisic_reward_func": 2, "set_num_parallel_env": 2, "set_train_mod": 2, "setup_model": 2, "shape": [2, 3], "short": 1, "simpl": 1, "singl": 2, "singleenv_m": 2, "size": 2, "slice": 2, "slice_tensor": 2, "so": 2, "soft": 2, "soft_exploit": 2, "soft_target_upd": 2, "some": [1, 2], "sorted_data_sub_indic": 3, "space": 2, "specifi": 2, "speed": 1, "squeez": 2, "start": [1, 2], "state": [1, 2, 3], "static": 2, "staticmethod": 2, "step": 2, "store": 2, "str": [2, 3], "straightforward": 1, "string": 2, "structur": 2, "subclass": 3, "subtract": 2, "summeri": 1, "suport": 2, "suppor": 1, "support": [1, 2], "take": 2, "taken": 2, "target": 2, "target_upd": 2, "target_update_count": 2, "tau": 2, "tensor": [2, 3], "tensorboard": [1, 2], "tensorboard_dir": 2, "termin": 2, "them": 2, "thi": [2, 3], "threshold": 2, "time": 2, "torch": [2, 3], "total": [2, 3], "tqdm": 2, "train": [1, 2, 3], "train_episodi": 2, "train_n_step": 2, "train_stat": 2, "train_stats_c": [], "trainmetr": 2, "true": [2, 3], "truncat": 2, "tupl": [2, 3], "type": 2, "unsqueez": 2, "up": 1, "updat": 2, "update_freq": 2, "update_polici": 2, "update_shap": 2, "us": [1, 2], "use_target": 2, "user": [1, 2], "util": 3, "v1": 2, "v2": [], "valu": 2, "vanila": 1, "vdqn": 1, "vdqn_agent": 0, "vector": 2, "wai": 2, "we": 1, "weak": 2, "when": [2, 3], "where": 2, "whether": 2, "which": 2, "without": 2, "work": 2, "worker": 2, "wrap": 2, "wrapper": 2, "writer": 2, "x": [2, 3], "ye": 1, "you": [1, 2], "your": 1, "zero": 2}, "titles": ["Welcome to RLify\u2019s documentation!", "Welcome", "rlify.agents package", "rlify.models package"], "titleterms": {"": 0, "action_spaces_util": 2, "agent": 2, "agent_util": 2, "base_model": 3, "content": 0, "contribut": 1, "ddpg_agent": 2, "document": 0, "dqn_agent": 2, "drl_agent": 2, "explor": 2, "fc": 3, "featur": 1, "heuristic_ag": 2, "indic": 0, "licens": 1, "model": 3, "model_factori": 3, "modul": [2, 3], "packag": [2, 3], "ppo_ag": 2, "progress": 1, "rlifi": [0, 1, 2, 3], "rnn": 3, "tabl": 0, "usag": 1, "vdqn_agent": 2, "welcom": [0, 1], "work": 1}})