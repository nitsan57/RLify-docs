Search.setIndex({"alltitles": {"Contents:": [[0, null]], "Contributions": [[1, "contributions"]], "Features": [[1, "features"]], "Indices and tables": [[0, "indices-and-tables"]], "License": [[1, "license"]], "RLify": [[1, "rlify"]], "Usage": [[1, "usage"]], "Welcome": [[1, "welcome"]], "Welcome to RLify\u2019s documentation!": [[0, "welcome-to-rlify-s-documentation"]], "Work in Progress": [[1, "work-in-progress"]], "rlify.agents package": [[2, "rlify-agents-package"]], "rlify.agents.action_spaces_utils module": [[2, "module-rlify.agents.action_spaces_utils"]], "rlify.agents.agent_utils module": [[2, "module-rlify.agents.agent_utils"]], "rlify.agents.ddpg_agent module": [[2, "module-rlify.agents.ddpg_agent"]], "rlify.agents.dqn_agent module": [[2, "module-rlify.agents.dqn_agent"]], "rlify.agents.drl_agent module": [[2, "module-rlify.agents.drl_agent"]], "rlify.agents.explorers module": [[2, "module-rlify.agents.explorers"]], "rlify.agents.heuristic_agent module": [[2, "module-rlify.agents.heuristic_agent"]], "rlify.agents.ppo_agent module": [[2, "module-rlify.agents.ppo_agent"]], "rlify.agents.vdqn_agent module": [[2, "module-rlify.agents.vdqn_agent"]], "rlify.models package": [[3, "rlify-models-package"]], "rlify.models.base_model module": [[3, "module-rlify.models.base_model"]], "rlify.models.fc module": [[3, "module-rlify.models.fc"]], "rlify.models.model_factory module": [[3, "module-rlify.models.model_factory"]], "rlify.models.rnn module": [[3, "module-rlify.models.rnn"]]}, "docnames": ["index", "readme_link", "rlify.agents", "rlify.models"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.rst", "readme_link.rst", "rlify.agents.rst", "rlify.models.rst"], "indexentries": {"__abstractmethods__ (rlify.agents.ddpg_agent.ddpg_agent attribute)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.dqn_agent.dqn_agent attribute)": [[2, "rlify.agents.dqn_agent.DQN_Agent.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.explorers.heuristicexplorer attribute)": [[2, "rlify.agents.explorers.HeuristicExplorer.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.explorers.randomexplorer attribute)": [[2, "rlify.agents.explorers.RandomExplorer.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.heuristic_agent.heuristic_agent attribute)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.ppo_agent.ppo_agent attribute)": [[2, "rlify.agents.ppo_agent.PPO_Agent.__abstractmethods__", false]], "__abstractmethods__ (rlify.agents.vdqn_agent.vdqn_agent attribute)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.__abstractmethods__", false]], "__add__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__add__", false]], "__annotations__ (rlify.agents.agent_utils.forgettingexperiencereplay attribute)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.__annotations__", false]], "__annotations__ (rlify.agents.ddpg_agent.ddpg_agent attribute)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.__annotations__", false]], "__annotations__ (rlify.agents.dqn_agent.dqn_agent attribute)": [[2, "rlify.agents.dqn_agent.DQN_Agent.__annotations__", false]], "__annotations__ (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer.__annotations__", false]], "__annotations__ (rlify.agents.explorers.heuristicexplorer attribute)": [[2, "rlify.agents.explorers.HeuristicExplorer.__annotations__", false]], "__annotations__ (rlify.agents.explorers.randomexplorer attribute)": [[2, "rlify.agents.explorers.RandomExplorer.__annotations__", false]], "__annotations__ (rlify.agents.heuristic_agent.heuristic_agent attribute)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.__annotations__", false]], "__annotations__ (rlify.agents.ppo_agent.ppo_agent attribute)": [[2, "rlify.agents.ppo_agent.PPO_Agent.__annotations__", false]], "__annotations__ (rlify.agents.vdqn_agent.vdqn_agent attribute)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.__annotations__", false]], "__del__() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.__del__", false]], "__del__() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.__del__", false]], "__del__() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.__del__", false]], "__delitem__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__delitem__", false]], "__dict__ (rlify.agents.action_spaces_utils.mcaw attribute)": [[2, "rlify.agents.action_spaces_utils.MCAW.__dict__", false]], "__dict__ (rlify.agents.action_spaces_utils.mda attribute)": [[2, "rlify.agents.action_spaces_utils.MDA.__dict__", false]], "__dict__ (rlify.agents.agent_utils.experiencereplay attribute)": [[2, "rlify.agents.agent_utils.ExperienceReplay.__dict__", false]], "__dict__ (rlify.agents.agent_utils.obsshapewraper attribute)": [[2, "rlify.agents.agent_utils.ObsShapeWraper.__dict__", false]], "__dict__ (rlify.agents.agent_utils.obswraper attribute)": [[2, "rlify.agents.agent_utils.ObsWraper.__dict__", false]], "__dict__ (rlify.agents.agent_utils.parallelenv attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv.__dict__", false]], "__dict__ (rlify.agents.agent_utils.parallelenv_m attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.__dict__", false]], "__dict__ (rlify.agents.agent_utils.singleenv_m attribute)": [[2, "rlify.agents.agent_utils.SingleEnv_m.__dict__", false]], "__dict__ (rlify.agents.agent_utils.trainmetrics attribute)": [[2, "rlify.agents.agent_utils.TrainMetrics.__dict__", false]], "__dict__ (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.__dict__", false]], "__dict__ (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer.__dict__", false]], "__getitem__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__getitem__", false]], "__getitem__() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.__getitem__", false]], "__init__() (rlify.agents.action_spaces_utils.caw method)": [[2, "rlify.agents.action_spaces_utils.CAW.__init__", false]], "__init__() (rlify.agents.action_spaces_utils.mcaw method)": [[2, "rlify.agents.action_spaces_utils.MCAW.__init__", false]], "__init__() (rlify.agents.action_spaces_utils.mda method)": [[2, "rlify.agents.action_spaces_utils.MDA.__init__", false]], "__init__() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.__init__", false]], "__init__() (rlify.agents.agent_utils.forgettingexperiencereplay method)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.__init__", false]], "__init__() (rlify.agents.agent_utils.obsshapewraper method)": [[2, "rlify.agents.agent_utils.ObsShapeWraper.__init__", false]], "__init__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__init__", false]], "__init__() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.__init__", false]], "__init__() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.__init__", false]], "__init__() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.__init__", false]], "__init__() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.__init__", false]], "__init__() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.__init__", false]], "__init__() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.__init__", false]], "__init__() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.__init__", false]], "__init__() (rlify.agents.explorers.explorer method)": [[2, "rlify.agents.explorers.Explorer.__init__", false]], "__init__() (rlify.agents.explorers.heuristicexplorer method)": [[2, "rlify.agents.explorers.HeuristicExplorer.__init__", false]], "__init__() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer.__init__", false]], "__init__() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.__init__", false]], "__init__() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.__init__", false]], "__init__() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.__init__", false]], "__iter__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__iter__", false]], "__iter__() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.__iter__", false]], "__len__() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.__len__", false]], "__len__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__len__", false]], "__module__ (rlify.agents.action_spaces_utils.caw attribute)": [[2, "rlify.agents.action_spaces_utils.CAW.__module__", false]], "__module__ (rlify.agents.action_spaces_utils.mcaw attribute)": [[2, "rlify.agents.action_spaces_utils.MCAW.__module__", false]], "__module__ (rlify.agents.action_spaces_utils.mda attribute)": [[2, "rlify.agents.action_spaces_utils.MDA.__module__", false]], "__module__ (rlify.agents.agent_utils.experiencereplay attribute)": [[2, "rlify.agents.agent_utils.ExperienceReplay.__module__", false]], "__module__ (rlify.agents.agent_utils.forgettingexperiencereplay attribute)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.__module__", false]], "__module__ (rlify.agents.agent_utils.obsshapewraper attribute)": [[2, "rlify.agents.agent_utils.ObsShapeWraper.__module__", false]], "__module__ (rlify.agents.agent_utils.obswraper attribute)": [[2, "rlify.agents.agent_utils.ObsWraper.__module__", false]], "__module__ (rlify.agents.agent_utils.parallelenv attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv.__module__", false]], "__module__ (rlify.agents.agent_utils.parallelenv_m attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.__module__", false]], "__module__ (rlify.agents.agent_utils.singleenv_m attribute)": [[2, "rlify.agents.agent_utils.SingleEnv_m.__module__", false]], "__module__ (rlify.agents.agent_utils.trainmetrics attribute)": [[2, "rlify.agents.agent_utils.TrainMetrics.__module__", false]], "__module__ (rlify.agents.ddpg_agent.ddpg_agent attribute)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.__module__", false]], "__module__ (rlify.agents.dqn_agent.dqn_agent attribute)": [[2, "rlify.agents.dqn_agent.DQN_Agent.__module__", false]], "__module__ (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.__module__", false]], "__module__ (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer.__module__", false]], "__module__ (rlify.agents.explorers.heuristicexplorer attribute)": [[2, "rlify.agents.explorers.HeuristicExplorer.__module__", false]], "__module__ (rlify.agents.explorers.randomexplorer attribute)": [[2, "rlify.agents.explorers.RandomExplorer.__module__", false]], "__module__ (rlify.agents.heuristic_agent.heuristic_agent attribute)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.__module__", false]], "__module__ (rlify.agents.ppo_agent.ppo_agent attribute)": [[2, "rlify.agents.ppo_agent.PPO_Agent.__module__", false]], "__module__ (rlify.agents.vdqn_agent.vdqn_agent attribute)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.__module__", false]], "__mul__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__mul__", false]], "__neg__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__neg__", false]], "__next__() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.__next__", false]], "__repr__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__repr__", false]], "__setitem__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__setitem__", false]], "__str__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__str__", false]], "__sub__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__sub__", false]], "__truediv__() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.__truediv__", false]], "__weakref__ (rlify.agents.action_spaces_utils.mcaw attribute)": [[2, "rlify.agents.action_spaces_utils.MCAW.__weakref__", false]], "__weakref__ (rlify.agents.action_spaces_utils.mda attribute)": [[2, "rlify.agents.action_spaces_utils.MDA.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.experiencereplay attribute)": [[2, "rlify.agents.agent_utils.ExperienceReplay.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.obsshapewraper attribute)": [[2, "rlify.agents.agent_utils.ObsShapeWraper.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.obswraper attribute)": [[2, "rlify.agents.agent_utils.ObsWraper.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.parallelenv attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.parallelenv_m attribute)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.singleenv_m attribute)": [[2, "rlify.agents.agent_utils.SingleEnv_m.__weakref__", false]], "__weakref__ (rlify.agents.agent_utils.trainmetrics attribute)": [[2, "rlify.agents.agent_utils.TrainMetrics.__weakref__", false]], "__weakref__ (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.__weakref__", false]], "__weakref__ (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer.__weakref__", false]], "_abc_impl (rlify.agents.ddpg_agent.ddpg_agent attribute)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent._abc_impl", false]], "_abc_impl (rlify.agents.dqn_agent.dqn_agent attribute)": [[2, "rlify.agents.dqn_agent.DQN_Agent._abc_impl", false]], "_abc_impl (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent._abc_impl", false]], "_abc_impl (rlify.agents.explorers.explorer attribute)": [[2, "rlify.agents.explorers.Explorer._abc_impl", false]], "_abc_impl (rlify.agents.explorers.heuristicexplorer attribute)": [[2, "rlify.agents.explorers.HeuristicExplorer._abc_impl", false]], "_abc_impl (rlify.agents.explorers.randomexplorer attribute)": [[2, "rlify.agents.explorers.RandomExplorer._abc_impl", false]], "_abc_impl (rlify.agents.heuristic_agent.heuristic_agent attribute)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent._abc_impl", false]], "_abc_impl (rlify.agents.ppo_agent.ppo_agent attribute)": [[2, "rlify.agents.ppo_agent.PPO_Agent._abc_impl", false]], "_abc_impl (rlify.agents.vdqn_agent.vdqn_agent attribute)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent._abc_impl", false]], "_act_cont() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer._act_cont", false]], "_act_discrete() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer._act_discrete", false]], "_get_dqn_experiences() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent._get_dqn_experiences", false]], "_get_ppo_experiences() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent._get_ppo_experiences", false]], "_init_from_none_() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper._init_from_none_", false]], "_train_n_iters() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent._train_n_iters", false]], "act() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.act", false]], "act() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.act", false]], "act() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.act", false]], "act() (rlify.agents.explorers.explorer method)": [[2, "rlify.agents.explorers.Explorer.act", false]], "act() (rlify.agents.explorers.heuristicexplorer method)": [[2, "rlify.agents.explorers.HeuristicExplorer.act", false]], "act() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer.act", false]], "act() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.act", false]], "act() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.act", false]], "act() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.act", false]], "act_base() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.act_base", false]], "act_base() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.act_base", false]], "actor_action() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.actor_action", false]], "add() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.add", false]], "append() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.append", false]], "append() (rlify.agents.agent_utils.forgettingexperiencereplay method)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.append", false]], "best_act_cont() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.best_act_cont", false]], "best_act_cont() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.best_act_cont", false]], "best_act_cont() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.best_act_cont", false]], "best_act_cont() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.best_act_cont", false]], "best_act_cont() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.best_act_cont", false]], "best_act_cont() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.best_act_cont", false]], "best_act_discrete() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.best_act_discrete", false]], "best_act_discrete() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.best_act_discrete", false]], "best_act_discrete() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.best_act_discrete", false]], "best_act_discrete() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.best_act_discrete", false]], "best_act_discrete() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.best_act_discrete", false]], "best_act_discrete() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.best_act_discrete", false]], "calc_gaes() (in module rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.calc_gaes", false]], "calc_returns() (in module rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.calc_returns", false]], "cat() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.cat", false]], "caw (class in rlify.agents.action_spaces_utils)": [[2, "rlify.agents.action_spaces_utils.CAW", false]], "change_env() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.change_env", false]], "change_env() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.change_env", false]], "change_env() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.change_env", false]], "clear() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.clear", false]], "clear_exp() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.clear_exp", false]], "clear_exp() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.clear_exp", false]], "close_env_procs() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.close_env_procs", false]], "close_procs() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.close_procs", false]], "close_procs() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.close_procs", false]], "close_procs() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.close_procs", false]], "collect_episode_obs() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.collect_episode_obs", false]], "ddpg_agent (class in rlify.agents.ddpg_agent)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent", false]], "define_action_space() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.define_action_space", false]], "dict_types (rlify.agents.agent_utils.obsshapewraper attribute)": [[2, "rlify.agents.agent_utils.ObsShapeWraper.dict_types", false]], "dqn_agent (class in rlify.agents.dqn_agent)": [[2, "rlify.agents.dqn_agent.DQN_Agent", false]], "entropy() (rlify.agents.action_spaces_utils.mcaw method)": [[2, "rlify.agents.action_spaces_utils.MCAW.entropy", false]], "entropy() (rlify.agents.action_spaces_utils.mda method)": [[2, "rlify.agents.action_spaces_utils.MDA.entropy", false]], "eval (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.EVAL", false]], "experiencereplay (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ExperienceReplay", false]], "explore() (rlify.agents.explorers.explorer method)": [[2, "rlify.agents.explorers.Explorer.explore", false]], "explore() (rlify.agents.explorers.heuristicexplorer method)": [[2, "rlify.agents.explorers.HeuristicExplorer.explore", false]], "explore() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer.explore", false]], "explorer (class in rlify.agents.explorers)": [[2, "rlify.agents.explorers.Explorer", false]], "forgettingexperiencereplay (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay", false]], "get_actor_action_value() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.get_actor_action_value", false]], "get_all_buffers() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_all_buffers", false]], "get_as_tensors() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.get_as_tensors", false]], "get_buffers_at() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_buffers_at", false]], "get_envs() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.get_envs", false]], "get_envs() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.get_envs", false]], "get_envs() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.get_envs", false]], "get_episode_end_indices() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_episode_end_indices", false]], "get_episode_start_indices() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_episode_start_indices", false]], "get_episodes_accumulated_rewards() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_episodes_accumulated_rewards", false]], "get_first_episodes() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_first_episodes", false]], "get_first_samples() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_first_samples", false]], "get_highest_score_agent_ckpt_path() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.get_highest_score_agent_ckpt_path", false]], "get_last_collected_experiences() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.get_last_collected_experiences", false]], "get_last_collected_experiences() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.get_last_collected_experiences", false]], "get_last_episodes() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_last_episodes", false]], "get_last_episodes() (rlify.agents.agent_utils.forgettingexperiencereplay method)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.get_last_episodes", false]], "get_last_samples() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_last_samples", false]], "get_metrcis_df() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.get_metrcis_df", false]], "get_models_input_output_shape() (rlify.agents.ddpg_agent.ddpg_agent static method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.get_models_input_output_shape", false]], "get_models_input_output_shape() (rlify.agents.dqn_agent.dqn_agent static method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.get_models_input_output_shape", false]], "get_models_input_output_shape() (rlify.agents.drl_agent.rl_agent static method)": [[2, "rlify.agents.drl_agent.RL_Agent.get_models_input_output_shape", false]], "get_models_input_output_shape() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.get_models_input_output_shape", false]], "get_models_input_output_shape() (rlify.agents.ppo_agent.ppo_agent static method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.get_models_input_output_shape", false]], "get_models_input_output_shape() (rlify.agents.vdqn_agent.vdqn_agent static method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.get_models_input_output_shape", false]], "get_num_samples_of_k_first_episodes() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_first_episodes", false]], "get_num_samples_of_k_last_episodes() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.get_num_samples_of_k_last_episodes", false]], "get_train_metrics() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.get_train_metrics", false]], "hard_target_update() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.hard_target_update", false]], "hard_target_update() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.hard_target_update", false]], "heuristic_agent (class in rlify.agents.heuristic_agent)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent", false]], "heuristicexplorer (class in rlify.agents.explorers)": [[2, "rlify.agents.explorers.HeuristicExplorer", false]], "init_buffers() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.init_buffers", false]], "init_buffers() (rlify.agents.agent_utils.forgettingexperiencereplay method)": [[2, "rlify.agents.agent_utils.ForgettingExperienceReplay.init_buffers", false]], "init_from_dict() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.init_from_dict", false]], "init_from_list_generic_data() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.init_from_list_generic_data", false]], "init_from_list_obswrapper_obs() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.init_from_list_obsWrapper_obs", false]], "init_target_update_rule() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.init_target_update_rule", false]], "init_tb_writer() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.init_tb_writer", false]], "intrisic_reward_func() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.intrisic_reward_func", false]], "items() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.items", false]], "keys() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.keys", false]], "load_agent() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.load_agent", false]], "load_agent() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.load_agent", false]], "load_agent() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.load_agent", false]], "load_agent() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.load_agent", false]], "load_agent() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.load_agent", false]], "load_agent() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.load_agent", false]], "load_highest_score_agent() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.load_highest_score_agent", false]], "loc (rlify.agents.action_spaces_utils.mcaw property)": [[2, "rlify.agents.action_spaces_utils.MCAW.loc", false]], "log_prob() (rlify.agents.action_spaces_utils.mcaw method)": [[2, "rlify.agents.action_spaces_utils.MCAW.log_prob", false]], "log_prob() (rlify.agents.action_spaces_utils.mda method)": [[2, "rlify.agents.action_spaces_utils.MDA.log_prob", false]], "mcaw (class in rlify.agents.action_spaces_utils)": [[2, "rlify.agents.action_spaces_utils.MCAW", false]], "mda (class in rlify.agents.action_spaces_utils)": [[2, "rlify.agents.action_spaces_utils.MDA", false]], "module": [[2, "module-rlify.agents.action_spaces_utils", false], [2, "module-rlify.agents.agent_utils", false], [2, "module-rlify.agents.ddpg_agent", false], [2, "module-rlify.agents.dqn_agent", false], [2, "module-rlify.agents.drl_agent", false], [2, "module-rlify.agents.explorers", false], [2, "module-rlify.agents.heuristic_agent", false], [2, "module-rlify.agents.ppo_agent", false], [2, "module-rlify.agents.vdqn_agent", false]], "norm_obs() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.norm_obs", false]], "np_append() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.np_append", false]], "np_cat() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.np_cat", false]], "np_roll() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.np_roll", false]], "np_zero_roll() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.np_zero_roll", false]], "obsshapewraper (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ObsShapeWraper", false]], "obswraper (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ObsWraper", false]], "on_epoch_end() (rlify.agents.agent_utils.trainmetrics method)": [[2, "rlify.agents.agent_utils.TrainMetrics.on_epoch_end", false]], "parallelenv (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ParallelEnv", false]], "parallelenv_m (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.ParallelEnv_m", false]], "ppo_agent (class in rlify.agents.ppo_agent)": [[2, "rlify.agents.ppo_agent.PPO_Agent", false]], "pre_process_obs_for_act() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.pre_process_obs_for_act", false]], "probs (rlify.agents.action_spaces_utils.mda property)": [[2, "rlify.agents.action_spaces_utils.MDA.probs", false]], "randomexplorer (class in rlify.agents.explorers)": [[2, "rlify.agents.explorers.RandomExplorer", false]], "read_action_space_properties() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.read_action_space_properties", false]], "read_obs_space_properties() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.read_obs_space_properties", false]], "render() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.render", false]], "render() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.render", false]], "render() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.render", false]], "reset() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.reset", false]], "reset() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.reset", false]], "reset() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.reset", false]], "reset_rnn_hidden() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.reset_rnn_hidden", false]], "reset_rnn_hidden() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.reset_rnn_hidden", false]], "reset_rnn_hidden() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.reset_rnn_hidden", false]], "reset_rnn_hidden() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.reset_rnn_hidden", false]], "reset_rnn_hidden() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.reset_rnn_hidden", false]], "reset_rnn_hidden() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.reset_rnn_hidden", false]], "return_correct_actions_dim() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.return_correct_actions_dim", false]], "rl_agent (class in rlify.agents.drl_agent)": [[2, "rlify.agents.drl_agent.RL_Agent", false]], "rlify.agents.action_spaces_utils": [[2, "module-rlify.agents.action_spaces_utils", false]], "rlify.agents.agent_utils": [[2, "module-rlify.agents.agent_utils", false]], "rlify.agents.ddpg_agent": [[2, "module-rlify.agents.ddpg_agent", false]], "rlify.agents.dqn_agent": [[2, "module-rlify.agents.dqn_agent", false]], "rlify.agents.drl_agent": [[2, "module-rlify.agents.drl_agent", false]], "rlify.agents.explorers": [[2, "module-rlify.agents.explorers", false]], "rlify.agents.heuristic_agent": [[2, "module-rlify.agents.heuristic_agent", false]], "rlify.agents.ppo_agent": [[2, "module-rlify.agents.ppo_agent", false]], "rlify.agents.vdqn_agent": [[2, "module-rlify.agents.vdqn_agent", false]], "run_env() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.run_env", false]], "sample() (rlify.agents.action_spaces_utils.caw method)": [[2, "rlify.agents.action_spaces_utils.CAW.sample", false]], "sample() (rlify.agents.action_spaces_utils.mcaw method)": [[2, "rlify.agents.action_spaces_utils.MCAW.sample", false]], "sample() (rlify.agents.action_spaces_utils.mda method)": [[2, "rlify.agents.action_spaces_utils.MDA.sample", false]], "sample_random_batch() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.sample_random_batch", false]], "sample_random_episodes() (rlify.agents.agent_utils.experiencereplay method)": [[2, "rlify.agents.agent_utils.ExperienceReplay.sample_random_episodes", false]], "save_agent() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.save_agent", false]], "save_agent() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.save_agent", false]], "save_agent() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.save_agent", false]], "save_agent() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.save_agent", false]], "save_agent() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.save_agent", false]], "save_agent() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.save_agent", false]], "scale (rlify.agents.action_spaces_utils.mcaw property)": [[2, "rlify.agents.action_spaces_utils.MCAW.scale", false]], "set_eval_mode() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.set_eval_mode", false]], "set_eval_mode() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.set_eval_mode", false]], "set_eval_mode() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.set_eval_mode", false]], "set_eval_mode() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.set_eval_mode", false]], "set_eval_mode() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.set_eval_mode", false]], "set_intrisic_reward_func() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.set_intrisic_reward_func", false]], "set_num_parallel_env() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.set_num_parallel_env", false]], "set_num_parallel_env() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.set_num_parallel_env", false]], "set_train_mode() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.set_train_mode", false]], "set_train_mode() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.set_train_mode", false]], "set_train_mode() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.set_train_mode", false]], "set_train_mode() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.set_train_mode", false]], "set_train_mode() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.set_train_mode", false]], "setup_models() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.setup_models", false]], "setup_models() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.setup_models", false]], "setup_models() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.setup_models", false]], "setup_models() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.setup_models", false]], "setup_models() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.setup_models", false]], "setup_models() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.setup_models", false]], "singleenv_m (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.SingleEnv_m", false]], "slice_tensors() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.slice_tensors", false]], "soft_target_update() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.soft_target_update", false]], "soft_target_update() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.soft_target_update", false]], "squeeze() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.squeeze", false]], "step() (rlify.agents.agent_utils.parallelenv method)": [[2, "rlify.agents.agent_utils.ParallelEnv.step", false]], "step() (rlify.agents.agent_utils.parallelenv_m method)": [[2, "rlify.agents.agent_utils.ParallelEnv_m.step", false]], "step() (rlify.agents.agent_utils.singleenv_m method)": [[2, "rlify.agents.agent_utils.SingleEnv_m.step", false]], "train (rlify.agents.drl_agent.rl_agent attribute)": [[2, "rlify.agents.drl_agent.RL_Agent.TRAIN", false]], "train() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.train", false]], "train_episodial() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.train_episodial", false]], "train_n_steps() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.train_n_steps", false]], "trainmetrics (class in rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.TrainMetrics", false]], "unsqueeze() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.unsqueeze", false]], "update() (rlify.agents.explorers.explorer method)": [[2, "rlify.agents.explorers.Explorer.update", false]], "update() (rlify.agents.explorers.heuristicexplorer method)": [[2, "rlify.agents.explorers.HeuristicExplorer.update", false]], "update() (rlify.agents.explorers.randomexplorer method)": [[2, "rlify.agents.explorers.RandomExplorer.update", false]], "update_policy() (rlify.agents.ddpg_agent.ddpg_agent method)": [[2, "rlify.agents.ddpg_agent.DDPG_Agent.update_policy", false]], "update_policy() (rlify.agents.dqn_agent.dqn_agent method)": [[2, "rlify.agents.dqn_agent.DQN_Agent.update_policy", false]], "update_policy() (rlify.agents.drl_agent.rl_agent method)": [[2, "rlify.agents.drl_agent.RL_Agent.update_policy", false]], "update_policy() (rlify.agents.heuristic_agent.heuristic_agent method)": [[2, "rlify.agents.heuristic_agent.Heuristic_Agent.update_policy", false]], "update_policy() (rlify.agents.ppo_agent.ppo_agent method)": [[2, "rlify.agents.ppo_agent.PPO_Agent.update_policy", false]], "update_policy() (rlify.agents.vdqn_agent.vdqn_agent method)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent.update_policy", false]], "update_shape() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.update_shape", false]], "values() (rlify.agents.agent_utils.obswraper method)": [[2, "rlify.agents.agent_utils.ObsWraper.values", false]], "vdqn_agent (class in rlify.agents.vdqn_agent)": [[2, "rlify.agents.vdqn_agent.VDQN_Agent", false]], "worker() (in module rlify.agents.agent_utils)": [[2, "rlify.agents.agent_utils.worker", false]]}, "objects": {"rlify.agents": [[2, 0, 0, "-", "action_spaces_utils"], [2, 0, 0, "-", "agent_utils"], [2, 0, 0, "-", "ddpg_agent"], [2, 0, 0, "-", "dqn_agent"], [2, 0, 0, "-", "drl_agent"], [2, 0, 0, "-", "explorers"], [2, 0, 0, "-", "heuristic_agent"], [2, 0, 0, "-", "ppo_agent"], [2, 0, 0, "-", "vdqn_agent"]], "rlify.agents.action_spaces_utils": [[2, 1, 1, "", "CAW"], [2, 1, 1, "", "MCAW"], [2, 1, 1, "", "MDA"]], "rlify.agents.action_spaces_utils.CAW": [[2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "sample"]], "rlify.agents.action_spaces_utils.MCAW": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 4, 1, "", "loc"], [2, 2, 1, "", "log_prob"], [2, 2, 1, "", "sample"], [2, 4, 1, "", "scale"]], "rlify.agents.action_spaces_utils.MDA": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 2, 1, "", "log_prob"], [2, 4, 1, "", "probs"], [2, 2, 1, "", "sample"]], "rlify.agents.agent_utils": [[2, 1, 1, "", "ExperienceReplay"], [2, 1, 1, "", "ForgettingExperienceReplay"], [2, 1, 1, "", "ObsShapeWraper"], [2, 1, 1, "", "ObsWraper"], [2, 1, 1, "", "ParallelEnv"], [2, 1, 1, "", "ParallelEnv_m"], [2, 1, 1, "", "SingleEnv_m"], [2, 1, 1, "", "TrainMetrics"], [2, 5, 1, "", "calc_gaes"], [2, 5, 1, "", "calc_returns"], [2, 5, 1, "", "worker"]], "rlify.agents.agent_utils.ExperienceReplay": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "clear"], [2, 2, 1, "", "get_all_buffers"], [2, 2, 1, "", "get_buffers_at"], [2, 2, 1, "", "get_episode_end_indices"], [2, 2, 1, "", "get_episode_start_indices"], [2, 2, 1, "", "get_episodes_accumulated_rewards"], [2, 2, 1, "", "get_first_episodes"], [2, 2, 1, "", "get_first_samples"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "get_last_samples"], [2, 2, 1, "", "get_num_samples_of_k_first_episodes"], [2, 2, 1, "", "get_num_samples_of_k_last_episodes"], [2, 2, 1, "", "init_buffers"], [2, 2, 1, "", "sample_random_batch"], [2, 2, 1, "", "sample_random_episodes"]], "rlify.agents.agent_utils.ForgettingExperienceReplay": [[2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "init_buffers"]], "rlify.agents.agent_utils.ObsShapeWraper": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "dict_types"]], "rlify.agents.agent_utils.ObsWraper": [[2, 2, 1, "", "__add__"], [2, 2, 1, "", "__delitem__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__getitem__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__iter__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "__mul__"], [2, 2, 1, "", "__neg__"], [2, 2, 1, "", "__repr__"], [2, 2, 1, "", "__setitem__"], [2, 2, 1, "", "__str__"], [2, 2, 1, "", "__sub__"], [2, 2, 1, "", "__truediv__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "_init_from_none_"], [2, 2, 1, "", "cat"], [2, 2, 1, "", "get_as_tensors"], [2, 2, 1, "", "init_from_dict"], [2, 2, 1, "", "init_from_list_generic_data"], [2, 2, 1, "", "init_from_list_obsWrapper_obs"], [2, 2, 1, "", "items"], [2, 2, 1, "", "keys"], [2, 2, 1, "", "np_append"], [2, 2, 1, "", "np_cat"], [2, 2, 1, "", "np_roll"], [2, 2, 1, "", "np_zero_roll"], [2, 2, 1, "", "slice_tensors"], [2, 2, 1, "", "squeeze"], [2, 2, 1, "", "unsqueeze"], [2, 2, 1, "", "update_shape"], [2, 2, 1, "", "values"]], "rlify.agents.agent_utils.ParallelEnv": [[2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.ParallelEnv_m": [[2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.SingleEnv_m": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlify.agents.agent_utils.TrainMetrics": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__getitem__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__iter__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "__next__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "add"], [2, 2, 1, "", "get_metrcis_df"], [2, 2, 1, "", "on_epoch_end"]], "rlify.agents.ddpg_agent": [[2, 1, 1, "", "DDPG_Agent"]], "rlify.agents.ddpg_agent.DDPG_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "actor_action"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "get_actor_action_value"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "hard_target_update"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "soft_target_update"], [2, 2, 1, "", "update_policy"]], "rlify.agents.dqn_agent": [[2, 1, 1, "", "DQN_Agent"]], "rlify.agents.dqn_agent.DQN_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "act_base"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "hard_target_update"], [2, 2, 1, "", "init_target_update_rule"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "soft_target_update"], [2, 2, 1, "", "update_policy"]], "rlify.agents.drl_agent": [[2, 1, 1, "", "RL_Agent"]], "rlify.agents.drl_agent.RL_Agent": [[2, 3, 1, "", "EVAL"], [2, 3, 1, "", "TRAIN"], [2, 3, 1, "", "__abstractmethods__"], [2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_train_n_iters"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "close_env_procs"], [2, 2, 1, "", "collect_episode_obs"], [2, 2, 1, "", "define_action_space"], [2, 2, 1, "", "get_highest_score_agent_ckpt_path"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "get_train_metrics"], [2, 2, 1, "", "init_tb_writer"], [2, 2, 1, "", "intrisic_reward_func"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "load_highest_score_agent"], [2, 2, 1, "", "norm_obs"], [2, 2, 1, "", "pre_process_obs_for_act"], [2, 2, 1, "", "read_action_space_properties"], [2, 2, 1, "", "read_obs_space_properties"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "return_correct_actions_dim"], [2, 2, 1, "", "run_env"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_intrisic_reward_func"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "train_episodial"], [2, 2, 1, "", "train_n_steps"], [2, 2, 1, "", "update_policy"]], "rlify.agents.explorers": [[2, 1, 1, "", "Explorer"], [2, 1, 1, "", "HeuristicExplorer"], [2, 1, 1, "", "RandomExplorer"]], "rlify.agents.explorers.Explorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.explorers.HeuristicExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.explorers.RandomExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_act_cont"], [2, 2, 1, "", "_act_discrete"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlify.agents.heuristic_agent": [[2, 1, 1, "", "Heuristic_Agent"]], "rlify.agents.heuristic_agent.Heuristic_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "train"], [2, 2, 1, "", "update_policy"]], "rlify.agents.ppo_agent": [[2, 1, 1, "", "PPO_Agent"]], "rlify.agents.ppo_agent.PPO_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_ppo_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "update_policy"]], "rlify.agents.vdqn_agent": [[2, 1, 1, "", "VDQN_Agent"]], "rlify.agents.vdqn_agent.VDQN_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_dqn_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "act_base"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "get_models_input_output_shape"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "setup_models"], [2, 2, 1, "", "update_policy"]], "rlify.models": [[3, 0, 0, "-", "base_model"], [3, 0, 0, "-", "fc"], [3, 0, 0, "-", "model_factory"], [3, 0, 0, "-", "rnn"]], "rlify.models.base_model": [[3, 1, 1, "", "BaseModel"]], "rlify.models.base_model.BaseModel": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 2, 1, "", "__init_subclass__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 4, 1, "", "device"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "get_total_params"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]], "rlify.models.fc": [[3, 1, 1, "", "FC"]], "rlify.models.fc.FC": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlify.models.model_factory": [[3, 5, 1, "", "get_model_class"]], "rlify.models.rnn": [[3, 1, 1, "", "GRU"], [3, 1, 1, "", "ReccurentLayer"], [3, 5, 1, "", "get_seqs_indices_for_pack"], [3, 5, 1, "", "pack_from_done_indices"]], "rlify.models.rnn.GRU": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlify.models.rnn.ReccurentLayer": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "terms": {"": [1, 2], "0": 2, "0001": 2, "0003": 2, "01": 2, "02438": 2, "03": 2, "05": 2, "0x7f23dd9957c0": [], "0x7f252f1957c0": [], "0x7f6dcff957c0": [], "0x7f73bf3957c0": [], "0x7f8108b957c0": [], "0x7f8c6e7957c0": [], "0x7f9d827957c0": [], "0x7fc2ed5957c0": 2, "0x7fce1d7957c0": [], "1": 2, "10": 2, "100000": [], "10000000": 2, "1024": 2, "10e6": 2, "128": 2, "1506": 2, "16": 2, "2": [2, 3], "250000": 2, "256": 2, "3": 2, "350000": [], "3e": 2, "4": 2, "5": 2, "64": [2, 3], "80000": 2, "9": 2, "99": 2, "A": [1, 2, 3], "And": 1, "For": 1, "If": [1, 2], "It": [1, 2, 3], "No": 1, "The": [2, 3], "__abstractmethods__": [2, 3], "__add__": 2, "__annotations__": [2, 3], "__call__": 3, "__del__": 2, "__delitem__": 2, "__dict__": 2, "__doc__": 2, "__getitem__": 2, "__init__": [2, 3], "__init_subclass__": 3, "__iter__": 2, "__len__": 2, "__module__": [2, 3], "__mul__": 2, "__neg__": 2, "__next__": 2, "__repr__": 2, "__setitem__": 2, "__str__": 2, "__sub__": 2, "__truediv__": 2, "__weakref__": 2, "_abc": [2, 3], "_abc_data": [2, 3], "_abc_impl": [2, 3], "_act_cont": 2, "_act_discret": 2, "_backward_hook": 3, "_backward_pre_hook": 3, "_buffer": 3, "_compiled_call_impl": 3, "_forward_hook": 3, "_forward_hooks_always_cal": 3, "_forward_hooks_with_kwarg": 3, "_forward_pre_hook": 3, "_forward_pre_hooks_with_kwarg": 3, "_get_dqn_experi": 2, "_get_ppo_experi": 2, "_init_from_none_": 2, "_is_full_backward_hook": 3, "_load_state_dict_post_hook": 3, "_load_state_dict_pre_hook": 3, "_modul": 3, "_non_persistent_buffers_set": 3, "_paramet": 3, "_state_dict_hook": 3, "_state_dict_pre_hook": 3, "_train_n_it": 2, "_version": 3, "abc": [2, 3], "about": 2, "absolut": 2, "abstract": [2, 3], "abstrcat": 2, "accord": 2, "act": 2, "act_bas": 2, "action": [1, 2], "action_dim": 2, "action_shap": 2, "action_spac": 2, "action_spaces_util": 0, "activ": [2, 3], "actor": 2, "actor_act": 2, "actual": 2, "ad": 1, "add": [1, 2], "addit": 2, "advantag": 2, "after": 2, "agent": [0, 1], "agent_c": 2, "agent_util": 0, "agnet": 2, "algorithm": [1, 2], "all": [1, 2, 3], "allow": 2, "also": [1, 2], "an": [1, 2], "ani": 3, "anoth": 2, "api": [1, 2], "append": 2, "ar": 2, "architectur": 1, "arg": [2, 3], "argument": 2, "arrai": 2, "arxiv": 2, "attr": 2, "attribut": 2, "availbl": 2, "axi": 2, "b": 2, "b_shape": 2, "base": [2, 3], "base_model": 0, "basemodel": [2, 3], "basic": [2, 3], "batch": 2, "batch_siz": 2, "best": 2, "best_act": 2, "best_act_cont": 2, "best_act_discret": 2, "bool": [2, 3], "bound": 2, "buffer": 2, "bug": 1, "built": 2, "cacul": 2, "calc_ga": 2, "calc_return": 2, "calcul": [2, 3], "call": [2, 3], "call_super_init": 3, "callabl": 3, "callback": [1, 2], "can": [1, 3], "capac": 2, "cartpol": 2, "case": 2, "cat": 2, "caw": 2, "certain": 1, "certein": 1, "chang": 2, "change_env": 2, "check": [1, 2], "choic": 1, "class": [2, 3], "classmethod": 3, "clear": 2, "clear_exp": 2, "clip": 2, "clip_param": 2, "clipe": 1, "clone": 1, "close": 2, "close_env_proc": 2, "close_proc": 2, "coeffici": 2, "collect": 2, "collect_episode_ob": 2, "compat": 1, "concaten": 2, "conn": 2, "connect": [2, 3], "consitst": 2, "contain": 2, "contin": 2, "continiuo": 2, "continous_mem": 2, "continu": [1, 2], "correct": 2, "could": 2, "cpu": 2, "creat": [1, 2], "critic_input_shap": 2, "critic_nn": 2, "critic_out_shap": 2, "curr": 1, "curr_ob": 2, "current": [1, 2], "custom": 2, "customiz": 1, "d": 3, "data": [2, 3], "datafram": 2, "ddpg": [1, 2], "ddpg_agent": 0, "ddqn": 1, "decai": 2, "deep": 1, "def": 2, "default": [2, 3], "defin": 2, "define_action_spac": 2, "delet": 2, "deploy": 1, "depth": [2, 3], "design": 1, "destructor": 2, "detail": 2, "determinist": 2, "detrminist": 2, "develop": 1, "devic": [2, 3], "dict": [2, 3], "dict_typ": 2, "dictionari": [1, 2], "dim": 2, "dimens": [2, 3], "diment": 2, "directori": 2, "disabl": 2, "disable_tqdm": 2, "discount": 2, "discount_factor": 2, "discret": [1, 2], "diverg": 2, "divid": 2, "do": 2, "doc": 1, "doe": [2, 3], "done": [2, 3], "done_indic": 3, "dq_reg": [], "dqn": [1, 2], "dqn_agent": 0, "dqn_reg": 2, "drl_agent": 0, "dummi": 2, "dummy_reward_func": 2, "dump": 1, "dump_patch": 3, "each": 2, "either": [1, 2], "els": 2, "embed": 3, "embed_dim": [2, 3], "empti": 2, "enhanc": 1, "entropi": 2, "entropy_coeff": 2, "env": [1, 2], "env_c": 2, "env_func": 2, "env_nam": 2, "environ": [1, 2], "epidsod": 2, "episod": 2, "epoch": 2, "eps_dec": 2, "eps_end": 2, "epsilon": 2, "estim": 2, "eval": 2, "evalu": 2, "everi": 2, "exampl": [1, 2], "exp": 2, "experi": 2, "experience_class": 2, "experiencereplai": 2, "exploit": 2, "explor": [0, 1], "exploration_epsilon": 2, "exprienc": 2, "extend": [1, 3], "f_name": 2, "facilit": 1, "factor": 2, "fals": [2, 3], "fc": [0, 2], "feel": 1, "file": 2, "fill": 2, "final": 2, "first": 2, "fix": [1, 2], "flexibl": 1, "float": 2, "follow": 1, "for_val": 2, "forc": 2, "forget": 2, "forgettingexperiencereplai": 2, "format": 1, "forward": 3, "framework": 1, "free": 1, "from": [1, 2, 3], "frozenset": [2, 3], "full": 2, "fulli": [1, 3], "func": 2, "function": [1, 2, 3], "futur": 2, "gener": 2, "get": [1, 2], "get_action_valu": [], "get_actor_action_valu": 2, "get_all_buff": 2, "get_as_tensor": 2, "get_buffers_at": 2, "get_env": 2, "get_episode_end_indic": 2, "get_episode_start_indic": 2, "get_episodes_accumulated_reward": 2, "get_first_episod": 2, "get_first_sampl": 2, "get_highest_score_agent_ckpt_path": 2, "get_last_collected_experi": 2, "get_last_episod": 2, "get_last_sampl": 2, "get_metrcis_df": 2, "get_model_class": 3, "get_models_input_output_shap": 2, "get_num_samples_of_k_first_episod": 2, "get_num_samples_of_k_last_episod": 2, "get_seqs_indices_for_pack": 3, "get_total_param": 3, "get_train_metr": 2, "given": 2, "good": 2, "gru": 3, "gym": [1, 2], "gymnasium": 2, "hard": 2, "hard_target_upd": 2, "helper": 2, "heurist": [1, 2], "heuristic_ag": 0, "heuristic_func": 2, "heuristic_funct": 2, "heuristicexplor": [1, 2], "heurstic": 1, "hidden": [2, 3], "hidden_dim": 3, "hidden_st": 2, "high": 2, "higher": 2, "highest": 2, "http": 2, "human": 1, "i": [1, 2, 3], "implement": [1, 3], "impliment": 2, "includ": 1, "index": [0, 2], "indic": [2, 3], "indx": 2, "info": 2, "inherit": 2, "init": 2, "init_buff": 2, "init_from_dict": 2, "init_from_list_generic_data": 2, "init_from_list_obswrapper_ob": 2, "init_target_update_rul": 2, "init_tb_writ": 2, "initi": 2, "inner": 2, "inner_st": 2, "inplac": 2, "input": [1, 2, 3], "input_shap": [2, 3], "int": [2, 3], "integr": 1, "interest": 1, "intrins": 1, "intrisic_reward_func": 2, "ipynb": 1, "is_rnn": 3, "issu": 1, "item": 2, "iter": 2, "just": [2, 3], "keep": 2, "keep_dim": 2, "kei": 2, "kl": 2, "kl_div_thresh": 2, "kwarg": [2, 3], "l2": 2, "last": 2, "leakyrelu": [], "learn": [1, 2], "len": 2, "length": 2, "linear": 2, "list": 2, "load": 2, "load_ag": 2, "load_highest_score_ag": 2, "loc": 2, "locs_scal": 2, "log": 2, "log_prob": 2, "logic": [1, 2], "logit": 2, "low": 2, "lower": 2, "lr": 2, "lunarland": [], "mai": 3, "main": 2, "mainli": 2, "make": 2, "mani": [1, 2], "manual_upd": 2, "map": 2, "mappingproxi": 2, "marl": 1, "max": 2, "max_episode_len": 2, "max_mem_s": 2, "maximum": 2, "mcaw": 2, "mda": 2, "mean": 2, "memori": 2, "method": [1, 2, 3], "metric": [1, 2], "metric_nam": 2, "mit": 1, "mle": 2, "mode": 2, "model": [0, 1, 2], "model_factori": 0, "model_typ": 3, "models_shap": 2, "modul": 0, "more": [1, 2], "multi": 2, "multipl": 2, "multipli": 2, "multivari": 2, "n": 2, "n_action": 2, "n_episod": 2, "n_iter": 2, "n_step": 2, "name": 2, "ndarrai": 2, "need": 2, "negat": 2, "negative_slop": [], "network": [1, 2], "neural": 1, "new": [1, 2], "next_stat": 2, "nn": [2, 3], "none": [2, 3], "noop": 2, "norm_ob": 2, "normal": 2, "normali": 2, "noth": [2, 3], "notic": 2, "now": 2, "np": 2, "np_append": 2, "np_cat": 2, "np_roll": 2, "np_zero_rol": 2, "num": 2, "num_env": 2, "num_episod": 2, "num_epochs_per_upd": 2, "num_gru": 3, "num_ob": 2, "num_parallel_env": 2, "num_run": 2, "num_sampl": 2, "num_to_collect_in_parallel": 2, "number": [2, 3], "number_of_episod": 2, "ob": 2, "object": [2, 3], "obs_list": 2, "obs_shap": 2, "obs_spac": 2, "observ": [1, 2], "observation_spac": 2, "obsshapewrap": 2, "obswrap": 2, "offset": 2, "ofrandom": 2, "old": 2, "oldest": 2, "on_epoch_end": 2, "onli": 2, "open": 1, "openai": 1, "oper": 2, "optim": [1, 2], "option": [2, 3], "order": 2, "org": 2, "other": 2, "out_shap": [2, 3], "output": [2, 3], "over": 2, "overrid": 1, "overridden": 3, "overwritten": 2, "own": 1, "pack": 3, "pack_from_done_indic": 3, "packag": 0, "packedsequ": 3, "page": 0, "pair": 2, "paper": 2, "parallel": 2, "parallelenv": 2, "parallelenv_m": 2, "param": 2, "paramet": [2, 3], "pass": 3, "path": 2, "pdf": 2, "pendulum": 2, "per": 2, "place": 2, "pleas": [1, 2], "pointwis": 2, "polici": [1, 2], "policy_input_shap": 2, "policy_nn": 2, "policy_out_shap": 2, "posit": 2, "possibl": 2, "possible_act": 2, "ppo": [1, 2], "ppo_ag": 0, "pre": 2, "pre_process_obs_for_act": 2, "print": 2, "prioritize_high_reward": 2, "prob": 2, "probabilti": 2, "process": 2, "properti": [2, 3], "provid": 1, "proxim": [1, 2], "pull": 1, "put": 2, "q": [1, 2], "q_input_shap": 2, "q_mle_input_shap": 2, "q_mle_model": 2, "q_mle_out_shap": 2, "q_model": 2, "q_out_shap": 2, "random": [1, 2], "random_sampl": 2, "randomexplor": 2, "rate": 2, "re": 1, "read_action_space_properti": 2, "read_obs_space_properti": 2, "reccurentlay": 3, "reciev": 2, "recurr": 1, "refer": 2, "regular": 2, "reinforc": [1, 2], "relev": 2, "relu": [2, 3], "render": 2, "render_mod": 2, "replai": 2, "repo": 1, "repr": 2, "represent": 2, "request": 1, "reset": [2, 3], "reset_rnn_hidden": 2, "respect": 2, "respons": 2, "return": [2, 3], "return_correct_actions_dim": 2, "reutn": 2, "reward": [1, 2], "reward_norm": 2, "rich": 1, "right": 2, "rl": [1, 2], "rl_agent": 2, "rnn": [0, 2], "robust": 1, "roll": 2, "roughli": 2, "rule": 2, "run": 2, "run_env": 2, "safe_check": 2, "sampl": 2, "sample_random_batch": 2, "sample_random_episod": 2, "sample_s": 2, "sample_shap": 2, "save": [1, 2], "save_ag": 2, "scale": 2, "score": 2, "seamlessli": 1, "search": 0, "select": 2, "self": 2, "separ": 2, "seq_len": 3, "sequenc": 3, "set": [1, 2, 3], "set_eval_mod": 2, "set_intrinsic_reward_func": 1, "set_intrisic_reward_func": 2, "set_num_parallel_env": 2, "set_train_mod": 2, "setup_model": 2, "shape": [2, 3], "short": 1, "simpl": 1, "singl": 2, "singleenv_m": 2, "size": 2, "slice": 2, "slice_tensor": 2, "so": 2, "soft": 2, "soft_exploit": 2, "soft_target_upd": 2, "some": [1, 2], "sorted_data_sub_indic": 3, "space": 2, "specifi": 2, "speed": 1, "squeez": 2, "start": [1, 2], "state": [1, 2, 3], "static": 2, "staticmethod": 2, "step": 2, "store": 2, "str": [2, 3], "straightforward": 1, "string": 2, "structur": 2, "subclass": 3, "subtract": 2, "summeri": 1, "suport": 2, "suppor": 1, "support": [1, 2], "take": 2, "taken": 2, "target": 2, "target_upd": 2, "target_update_count": 2, "tau": 2, "tensor": [2, 3], "tensorboard": [1, 2], "tensorboard_dir": 2, "termin": 2, "them": 2, "thi": [2, 3], "threshold": 2, "time": 2, "torch": [2, 3], "total": [2, 3], "tqdm": 2, "train": [1, 2, 3], "train_episodi": 2, "train_n_step": 2, "train_stat": 2, "train_stats_c": [], "trainmetr": 2, "true": [2, 3], "truncat": 2, "tupl": [2, 3], "type": 2, "unsqueez": 2, "up": 1, "updat": 2, "update_freq": 2, "update_polici": 2, "update_shap": 2, "us": [1, 2], "use_target": 2, "user": [1, 2], "util": 3, "v1": 2, "v2": [], "valu": 2, "vanila": 1, "vdqn": 1, "vdqn_agent": 0, "vector": 2, "wai": 2, "we": 1, "weak": 2, "when": [2, 3], "where": 2, "whether": 2, "which": 2, "without": 2, "work": 2, "worker": 2, "wrap": 2, "wrapper": 2, "writer": 2, "x": [2, 3], "ye": 1, "you": [1, 2], "your": 1, "zero": 2}, "titles": ["Welcome to RLify\u2019s documentation!", "Welcome", "rlify.agents package", "rlify.models package"], "titleterms": {"": 0, "action_spaces_util": 2, "agent": 2, "agent_util": 2, "base_model": 3, "content": 0, "contribut": 1, "ddpg_agent": 2, "document": 0, "dqn_agent": 2, "drl_agent": 2, "explor": 2, "fc": 3, "featur": 1, "heuristic_ag": 2, "indic": 0, "licens": 1, "model": 3, "model_factori": 3, "modul": [2, 3], "packag": [2, 3], "ppo_ag": 2, "progress": 1, "rlifi": [0, 1, 2, 3], "rnn": 3, "tabl": 0, "usag": 1, "vdqn_agent": 2, "welcom": [0, 1], "work": 1}})