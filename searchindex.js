Search.setIndex({"docnames": ["index", "readme_link", "rlkit.agents", "rlkit.models"], "filenames": ["index.rst", "readme_link.rst", "rlkit.agents.rst", "rlkit.models.rst"], "titles": ["Welcome to RLkit\u2019s documentation!", "Welcome", "rlkit.agents package", "rlkit.models package"], "terms": {"rl": [0, 2], "kit": 0, "agent": [0, 1], "packag": 0, "drl_agent": 0, "modul": 0, "dqn_agent": 0, "ppo_ag": 0, "explor": [0, 1], "action_spaces_util": 0, "agent_util": 0, "model": [0, 1, 2], "base_model": 0, "fc": 0, "model_factori": 0, "rnn": [0, 2], "index": 0, "search": 0, "page": 0, "i": [1, 2, 3], "robust": 1, "flexibl": 1, "reinforc": [1, 2], "learn": [1, 2], "framework": 1, "It": [1, 2, 3], "provid": 1, "rich": 1, "set": [1, 2, 3], "facilit": 1, "develop": 1, "train": [1, 2, 3], "deploy": 1, "algorithm": [1, 2], "clone": 1, "repo": 1, "also": 1, "check": [1, 2], "doc": 1, "For": 1, "exampl": [1, 2], "pleas": [1, 2], "get": [1, 2], "start": [1, 2], "ipynb": 1, "support": [1, 2], "current": [1, 2], "follow": 1, "proxim": [1, 2], "polici": [1, 2], "optim": [1, 2], "ppo": [1, 2], "deep": 1, "q": [1, 2], "network": [1, 2], "ddqn": 1, "gym": [1, 2], "api": 1, "compat": 1, "design": 1, "seamlessli": 1, "environ": [1, 2], "implement": [1, 3], "openai": 1, "customiz": 1, "you": 1, "can": [1, 3], "creat": [1, 2], "extend": [1, 3], "your": 1, "own": 1, "overrid": 1, "certain": 1, "function": [1, 2, 3], "neural": [1, 2], "": [1, 2], "straightforward": 1, "integr": 1, "includ": [1, 2], "recurr": 1, "fulli": 1, "intrins": 1, "reward": [1, 2], "simpl": 1, "us": [1, 2], "set_intrinsic_reward_func": 1, "method": [1, 2, 3], "heurist": [1, 2], "from": [1, 2], "random": [1, 2], "choic": 1, "some": [1, 2], "user": [1, 2], "input": 1, "heurstic": 1, "speed": 1, "up": 1, "certein": 1, "env": [1, 2], "heuristicexplor": [1, 2], "observ": [1, 2], "dictionari": [1, 2], "format": 1, "metric": 1, "dump": 1, "all": [1, 2, 3], "tensorboard": [1, 2], "And": 1, "mani": [1, 2], "more": 1, "A": [1, 2], "short": 1, "summeri": 1, "curr": 1, "discret": [1, 2], "action": [1, 2], "continu": [1, 2], "clipe": 1, "ye": 1, "dqn": [1, 2], "No": 1, "In": [], "thi": [2, 3], "tabl": [], "first": [], "column": [], "repres": [], "name": 2, "The": [2, 3], "second": [], "indic": 2, "whether": 2, "third": [], "last": 2, "architectur": 1, "note": [], "content": [], "base": [2, 3], "gener": 2, "inform": [], "mai": 3, "vari": [], "depend": [], "specif": [], "version": [], "add": 1, "callback": [1, 2], "suppor": 1, "marl": 1, "we": [1, 2], "If": 1, "re": 1, "interest": 1, "enhanc": 1, "fix": 1, "bug": 1, "ad": 1, "new": 1, "feel": 1, "free": 1, "open": 1, "pull": 1, "request": 1, "issu": 1, "mit": 1, "contain": 2, "helper": 2, "class": [2, 3], "rl_agent": 2, "obs_spac": 2, "action_spac": 2, "max_mem_s": 2, "10000000": 2, "0": 2, "batch_siz": 2, "256": 2, "randomexplor": 2, "object": [2, 3], "num_parallel_env": 2, "4": 2, "model_class": 2, "none": [2, 3], "model_kwarg": 2, "lr": 2, "0001": 2, "devic": 2, "experience_class": 2, "experiencereplai": 2, "discount_factor": 2, "99": 2, "tensorboard_dir": 2, "abc": [2, 3], "an": [1, 2], "abstract": [2, 3], "defin": [2, 3], "basic": 2, "structur": 2, "eval": 2, "1": 2, "__init__": [2, 3], "paramet": [2, 3], "space": 2, "int": [2, 3], "option": [2, 3], "maximum": 2, "size": 2, "experi": 2, "replai": 2, "buffer": 2, "default": [2, 3], "10e6": 2, "batch": 2, "number": 2, "parallel": 2, "abstractmodel": [2, 3], "dict": [2, 3], "kwarg": 2, "float": 2, "rate": 2, "torch": 2, "run": [2, 3], "str": [2, 3], "directori": 2, "init_tb_writ": 2, "init_model": 2, "update_polici": 2, "exp": 2, "get_train_metr": 2, "define_action_spac": 2, "__del__": 2, "save_ag": 2, "f_name": 2, "return": [2, 3], "type": 2, "load_ag": 2, "set_train_mod": 2, "set_eval_mod": 2, "train_episodi": 2, "n_episod": 2, "max_episode_len": 2, "disable_tqdm": 2, "fals": [2, 3], "train_n_step": 2, "n_step": 2, "_train_n_it": 2, "n_iter": 2, "episod": 2, "true": [2, 3], "each": 2, "iter": 2, "otherwis": [2, 3], "step": 2, "set_num_parallel_env": 2, "act": 2, "num_ob": 2, "extra_info": 2, "load_highest_score_ag": 2, "get_highest_score_agent_ckpt_path": 2, "best_act_discret": 2, "best_act_cont": 2, "get_seqs_indices_for_pack": [2, 3], "done_indic": [2, 3], "seq_len": [2, 3], "sorted_data_sub_indic": [2, 3], "pack_from_done_indic": [2, 3], "data": [2, 3], "seq_indic": 2, "sorted_seq_len": 2, "pakc": [2, 3], "ob": [2, 3], "pack_sorted_data": 2, "sorted_data": 2, "pack_sorted_data_h": 2, "norm_ob": 2, "pre_process_obs_for_act": 2, "return_correct_actions_dim": 2, "selected_act": 2, "close_env_proc": 2, "set_intrisic_reward_func": 2, "func": 2, "inner": 2, "custom": 2, "take": [2, 3], "state": [2, 3], "observation_spac": 2, "def": 2, "dummy_reward_func": 2, "now": 2, "normali": 2, "intrisic_reward_func": 2, "collect_episode_ob": 2, "num_to_collect_in_parallel": 2, "env_func": 2, "reset": [2, 3], "collect": 2, "length": 2, "map": 2, "call": [2, 3], "total": 2, "reset_rnn_hidden": 2, "place": 2, "so": 2, "impliment": 2, "__abstractmethods__": [2, 3], "frozenset": [2, 3], "clear_exp": 2, "get_last_collected_experi": 2, "__dict__": 2, "mappingproxi": 2, "__module__": [2, 3], "__doc__": 2, "n": 2, "run_env": 2, "attribut": 2, "__weakref__": 2, "_abc_impl": [2, 3], "_abc": [2, 3], "_abc_data": [2, 3], "__annotations__": [2, 3], "list": 2, "weak": 2, "refer": 2, "number_of_episod": 2, "best_act": 2, "num_run": 2, "dqn_reg": 2, "target_update_tim": 2, "100": 2, "64": [2, 3], "soft_exploit": 2, "env_nam": 2, "cartpol": 2, "v1": 2, "env_c": 2, "make": 2, "render_mod": 2, "agent_c": 2, "train_stats_c": 2, "100000": 2, "l2": 2, "regular": 2, "how": 2, "often": 2, "updat": 2, "target": 2, "bool": [2, 3], "soft": 2, "exploit": 2, "addit": 2, "argument": 2, "initi": [2, 3], "mode": 2, "hard_target_upd": 2, "hard": 2, "soft_target_upd": 2, "\u03b8_target": 2, "\u03c4": 2, "\u03b8_local": 2, "local_model": 2, "pytorch": 2, "weight": 2, "copi": 2, "target_model": 2, "tau": 2, "interpol": 2, "best": 2, "save": 2, "file": 2, "load": 2, "act_bas": 2, "onli": 2, "nn": [2, 3], "hidden_st": 2, "_get_dqn_experi": 2, "mix": 2, "sampl": 2, "sure": 2, "dont": 2, "miss": 2, "ani": [2, 3], "seen": 2, "num_episod": 2, "mainli": 2, "pair": 2, "1024": 2, "entropy_coeff": 2, "num_epochs_per_upd": 2, "10": 2, "kl_div_thresh": 2, "03": 2, "clip_param": 2, "forgettingexperiencereplaybeta": 2, "inherit": 2, "gymnasium": 2, "lunarland": 2, "v2": 2, "train_stat": 2, "350000": 2, "entropi": 2, "coeffici": 2, "epoch": 2, "per": 2, "kl": 2, "diverg": 2, "threshold": 2, "clip": 2, "save_dict": 2, "arg": 2, "_get_ppo_experi": 2, "safe_check": 2, "suport": 2, "random_sampl": 2, "tupl": 2, "linear": 2, "classmethod": [2, 3], "exploration_epsilon": 2, "eps_end": 2, "05": 2, "eps_dec": 2, "01": 2, "act_discret": 2, "act_cont": 2, "heuristic_funct": 2, "init": 2, "epsilon": 2, "mcaw": 2, "low": 2, "high": 2, "locs_scal": 2, "sample_shap": 2, "log_prob": 2, "properti": 2, "loc": 2, "scale": 2, "caw": 2, "normal": 2, "shape": 2, "distribut": 2, "ar": 2, "mda": 2, "possible_act": 2, "n_action": 2, "x": [2, 3], "multivari": 2, "np": 2, "arrai": 2, "offset": 2, "possibl": 2, "tensor": [2, 3], "logit": 2, "prob": 2, "calc_ga": 2, "valu": 2, "termin": 2, "decai": 2, "9": 2, "work": 2, "vector": 2, "which": 2, "consitst": 2, "epidsod": 2, "advantag": 2, "estim": 2, "given": 2, "paper": 2, "http": 2, "arxiv": 2, "org": 2, "pdf": 2, "1506": 2, "02438": 2, "obsshapewrap": 2, "obs_shap": 2, "dict_typ": 2, "obswrap": 2, "keep_dim": 2, "update_shap": 2, "init_from_list_obswrapper_ob": 2, "obs_list": 2, "init_from_list_generic_data": 2, "_init_from_none_": 2, "__setitem__": 2, "kei": 2, "__iter__": 2, "__getitem__": 2, "slice_tensor": 2, "item": 2, "__len__": 2, "__str__": 2, "self": 2, "__repr__": 2, "repr": 2, "__mul__": 2, "other": 2, "__add__": 2, "__neg__": 2, "__sub__": 2, "__truediv__": 2, "get_as_tensor": 2, "cpu": 2, "np_cat": 2, "axi": 2, "np_append": 2, "cat": 2, "np_zero_rol": 2, "indx": 2, "inplac": 2, "roll": 2, "fill": 2, "empti": 2, "zero": 2, "np_roll": 2, "capac": 2, "continous_mem": 2, "append": 2, "curr_ob": 2, "done": [2, 3], "truncat": 2, "init_buff": 2, "clear": 2, "get_last_episod": 2, "specifi": 2, "num": 2, "get_last_sampl": 2, "num_sampl": 2, "get_all_buff": 2, "get_buffers_at": 2, "sample_random_batch": 2, "sample_s": 2, "experiencereplaybeta": 2, "worker": 2, "conn": 2, "parallelenv": 2, "num_env": 2, "for_val": 2, "change_env": 2, "get_env": 2, "step_gener": 2, "clear_env": 2, "close_proc": 2, "render": 2, "parallelenv_m": 2, "singleenv_m": 2, "input_shap": 3, "out_shap": 3, "is_rnn": 3, "intern": 3, "share": 3, "both": 3, "scriptmodul": 3, "get_total_param": 3, "__init_subclass__": 3, "when": 3, "subclass": 3, "doe": 3, "noth": 3, "overridden": 3, "forward": 3, "comput": 3, "perform": 3, "everi": 3, "should": 3, "although": 3, "recip": 3, "pass": 3, "need": 3, "within": 3, "one": 3, "instanc": 3, "afterward": 3, "instead": 3, "sinc": 3, "former": 3, "care": 3, "regist": 3, "hook": 3, "while": 3, "latter": 3, "silent": 3, "ignor": 3, "them": 3, "__call__": 3, "callabl": 3, "_backward_hook": 3, "_backward_pre_hook": 3, "_buffer": 3, "_forward_hook": 3, "_forward_hooks_with_kwarg": 3, "_forward_pre_hook": 3, "_forward_pre_hooks_with_kwarg": 3, "_is_full_backward_hook": 3, "_load_state_dict_post_hook": 3, "_load_state_dict_pre_hook": 3, "_modul": 3, "_non_persistent_buffers_set": 3, "_paramet": 3, "_state_dict_hook": 3, "_state_dict_pre_hook": 3, "_version": 3, "call_super_init": 3, "dump_patch": 3, "impl": 3, "just": 3, "hidden": 3, "embed_dim": 3, "128": 3, "repeat": 3, "3": 3, "d": 3, "get_model_class": 3, "model_typ": 3, "reccurentlay": 3, "gru": 3, "hidden_dim": 3, "num_gru": 3, "2": 3, "pad": 3, "pack": 3, "writer": 2, "either": 1}, "objects": {"rlkit.agents": [[2, 0, 0, "-", "action_spaces_utils"], [2, 0, 0, "-", "agent_utils"], [2, 0, 0, "-", "dqn_agent"], [2, 0, 0, "-", "drl_agent"], [2, 0, 0, "-", "explorers"], [2, 0, 0, "-", "ppo_agent"]], "rlkit.agents.action_spaces_utils": [[2, 1, 1, "", "CAW"], [2, 1, 1, "", "MCAW"], [2, 1, 1, "", "MDA"]], "rlkit.agents.action_spaces_utils.CAW": [[2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "sample"]], "rlkit.agents.action_spaces_utils.MCAW": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 4, 1, "", "loc"], [2, 2, 1, "", "log_prob"], [2, 2, 1, "", "sample"], [2, 4, 1, "", "scale"]], "rlkit.agents.action_spaces_utils.MDA": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "entropy"], [2, 2, 1, "", "log_prob"], [2, 4, 1, "", "probs"], [2, 2, 1, "", "sample"]], "rlkit.agents.agent_utils": [[2, 1, 1, "", "ExperienceReplay"], [2, 1, 1, "", "ExperienceReplayBeta"], [2, 1, 1, "", "ForgettingExperienceReplayBeta"], [2, 1, 1, "", "ObsShapeWraper"], [2, 1, 1, "", "ObsWraper"], [2, 1, 1, "", "ParallelEnv"], [2, 1, 1, "", "ParallelEnv_m"], [2, 1, 1, "", "SingleEnv_m"], [2, 5, 1, "", "calc_gaes"], [2, 5, 1, "", "worker"]], "rlkit.agents.agent_utils.ExperienceReplay": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "clear"], [2, 2, 1, "", "get_all_buffers"], [2, 2, 1, "", "get_buffers_at"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "get_last_samples"], [2, 2, 1, "", "init_buffers"], [2, 2, 1, "", "sample_random_batch"]], "rlkit.agents.agent_utils.ExperienceReplayBeta": [[2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "init_buffers"]], "rlkit.agents.agent_utils.ForgettingExperienceReplayBeta": [[2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "append"], [2, 2, 1, "", "get_last_episodes"], [2, 2, 1, "", "init_buffers"]], "rlkit.agents.agent_utils.ObsShapeWraper": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "dict_types"]], "rlkit.agents.agent_utils.ObsWraper": [[2, 2, 1, "", "__add__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__getitem__"], [2, 2, 1, "", "__init__"], [2, 2, 1, "", "__iter__"], [2, 2, 1, "", "__len__"], [2, 3, 1, "", "__module__"], [2, 2, 1, "", "__mul__"], [2, 2, 1, "", "__neg__"], [2, 2, 1, "", "__repr__"], [2, 2, 1, "", "__setitem__"], [2, 2, 1, "", "__str__"], [2, 2, 1, "", "__sub__"], [2, 2, 1, "", "__truediv__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "_init_from_none_"], [2, 2, 1, "", "cat"], [2, 2, 1, "", "get_as_tensors"], [2, 2, 1, "", "init_from_list_generic_data"], [2, 2, 1, "", "init_from_list_obsWrapper_obs"], [2, 2, 1, "", "items"], [2, 2, 1, "", "keys"], [2, 2, 1, "", "np_append"], [2, 2, 1, "", "np_cat"], [2, 2, 1, "", "np_roll"], [2, 2, 1, "", "np_zero_roll"], [2, 2, 1, "", "slice_tensors"], [2, 2, 1, "", "update_shape"], [2, 2, 1, "", "values"]], "rlkit.agents.agent_utils.ParallelEnv": [[2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "clear_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"], [2, 2, 1, "", "step_generator"]], "rlkit.agents.agent_utils.ParallelEnv_m": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlkit.agents.agent_utils.SingleEnv_m": [[2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 2, 1, "", "change_env"], [2, 2, 1, "", "close_procs"], [2, 2, 1, "", "get_envs"], [2, 2, 1, "", "render"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "step"]], "rlkit.agents.dqn_agent": [[2, 1, 1, "", "DQN_Agent"]], "rlkit.agents.dqn_agent.DQN_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_dqn_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "act_base"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "hard_target_update"], [2, 2, 1, "", "init_models"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "soft_target_update"], [2, 2, 1, "", "train"], [2, 2, 1, "", "update_policy"]], "rlkit.agents.drl_agent": [[2, 1, 1, "", "RL_Agent"]], "rlkit.agents.drl_agent.RL_Agent": [[2, 3, 1, "", "EVAL"], [2, 3, 1, "", "TRAIN"], [2, 3, 1, "", "__abstractmethods__"], [2, 2, 1, "", "__del__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_train_n_iters"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "close_env_procs"], [2, 2, 1, "", "collect_episode_obs"], [2, 2, 1, "", "define_action_space"], [2, 2, 1, "", "get_highest_score_agent_ckpt_path"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "get_seqs_indices_for_pack"], [2, 2, 1, "", "get_train_metrics"], [2, 2, 1, "", "init_models"], [2, 2, 1, "", "init_tb_writer"], [2, 2, 1, "", "intrisic_reward_func"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "load_highest_score_agent"], [2, 2, 1, "", "norm_obs"], [2, 2, 1, "", "pack_from_done_indices"], [2, 2, 1, "", "pack_sorted_data"], [2, 2, 1, "", "pack_sorted_data_h"], [2, 2, 1, "", "pre_process_obs_for_act"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "return_correct_actions_dim"], [2, 2, 1, "", "run_env"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_intrisic_reward_func"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "train_episodial"], [2, 2, 1, "", "train_n_steps"], [2, 2, 1, "", "update_policy"]], "rlkit.agents.explorers": [[2, 1, 1, "", "Explorer"], [2, 1, 1, "", "HeuristicExplorer"], [2, 1, 1, "", "RandomExplorer"]], "rlkit.agents.explorers.Explorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 3, 1, "", "__dict__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "__weakref__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlkit.agents.explorers.HeuristicExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlkit.agents.explorers.RandomExplorer": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "act"], [2, 2, 1, "", "act_cont"], [2, 2, 1, "", "act_discrete"], [2, 2, 1, "", "explore"], [2, 2, 1, "", "update"]], "rlkit.agents.ppo_agent": [[2, 1, 1, "", "PPO_Agent"]], "rlkit.agents.ppo_agent.PPO_Agent": [[2, 3, 1, "", "__abstractmethods__"], [2, 3, 1, "", "__annotations__"], [2, 2, 1, "", "__init__"], [2, 3, 1, "", "__module__"], [2, 3, 1, "", "_abc_impl"], [2, 2, 1, "", "_get_ppo_experiences"], [2, 2, 1, "", "act"], [2, 2, 1, "", "best_act_cont"], [2, 2, 1, "", "best_act_discrete"], [2, 2, 1, "", "clear_exp"], [2, 2, 1, "", "collect_episode_obs"], [2, 2, 1, "", "get_last_collected_experiences"], [2, 2, 1, "", "init_models"], [2, 2, 1, "", "load_agent"], [2, 2, 1, "", "reset_rnn_hidden"], [2, 2, 1, "", "save_agent"], [2, 2, 1, "", "set_eval_mode"], [2, 2, 1, "", "set_num_parallel_env"], [2, 2, 1, "", "set_train_mode"], [2, 2, 1, "", "train"], [2, 2, 1, "", "update_policy"]], "rlkit.models": [[3, 0, 0, "-", "base_model"], [3, 0, 0, "-", "fc"], [3, 0, 0, "-", "model_factory"], [3, 0, 0, "-", "rnn"]], "rlkit.models.base_model": [[3, 1, 1, "", "AbstractModel"]], "rlkit.models.base_model.AbstractModel": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 2, 1, "", "__init_subclass__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "get_total_params"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]], "rlkit.models.fc": [[3, 1, 1, "", "FC"]], "rlkit.models.fc.FC": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlkit.models.model_factory": [[3, 5, 1, "", "get_model_class"]], "rlkit.models.rnn": [[3, 1, 1, "", "GRU"], [3, 1, 1, "", "ReccurentLayer"], [3, 5, 1, "", "get_seqs_indices_for_pack"], [3, 5, 1, "", "pack_from_done_indices"]], "rlkit.models.rnn.GRU": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "reset"]], "rlkit.models.rnn.ReccurentLayer": [[3, 3, 1, "", "__abstractmethods__"], [3, 3, 1, "", "__annotations__"], [3, 2, 1, "", "__init__"], [3, 3, 1, "", "__module__"], [3, 3, 1, "", "_abc_impl"], [3, 2, 1, "", "forward"], [3, 3, 1, "", "is_rnn"], [3, 2, 1, "", "reset"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "titleterms": {"welcom": [0, 1], "rlkit": [0, 2, 3], "": 0, "document": 0, "content": 0, "indic": 0, "tabl": 0, "rl": 1, "kit": 1, "usag": 1, "featur": 1, "work": 1, "progress": 1, "contribut": 1, "licens": 1, "agent": 2, "packag": [2, 3], "drl_agent": 2, "modul": [2, 3], "dqn_agent": 2, "param": 2, "ppo_ag": 2, "explor": 2, "action_spaces_util": 2, "agent_util": 2, "model": 3, "base_model": 3, "fc": 3, "model_factori": 3, "rnn": 3}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Welcome to RLkit\u2019s documentation!": [[0, "welcome-to-rlkit-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "rlkit.agents package": [[2, "rlkit-agents-package"]], "rlkit.agents.drl_agent module": [[2, "module-rlkit.agents.drl_agent"]], "rlkit.agents.dqn_agent module": [[2, "module-rlkit.agents.dqn_agent"]], "Params": [[2, "params"]], "rlkit.agents.ppo_agent module": [[2, "module-rlkit.agents.ppo_agent"]], "rlkit.agents.explorers module": [[2, "module-rlkit.agents.explorers"]], "rlkit.agents.action_spaces_utils module": [[2, "module-rlkit.agents.action_spaces_utils"]], "rlkit.agents.agent_utils module": [[2, "module-rlkit.agents.agent_utils"]], "rlkit.models package": [[3, "rlkit-models-package"]], "rlkit.models.base_model module": [[3, "module-rlkit.models.base_model"]], "rlkit.models.fc module": [[3, "module-rlkit.models.fc"]], "rlkit.models.model_factory module": [[3, "module-rlkit.models.model_factory"]], "rlkit.models.rnn module": [[3, "module-rlkit.models.rnn"]], "Welcome": [[1, "welcome"]], "RL Kit": [[1, "rl-kit"]], "Usage": [[1, "usage"]], "Features": [[1, "features"]], "Work in Progress": [[1, "work-in-progress"]], "Contributions": [[1, "contributions"]], "License": [[1, "license"]]}, "indexentries": {}})